# 字节质量技术组一面 8.18

## 1、如果一段SQL执行缓慢，你该如何排查？

### 1. **查看执行计划（EXPLAIN）**

- 使用 `EXPLAIN` 或 `EXPLAIN ANALYZE` 查看 SQL 的执行计划，分析 SQL 语句的执行步骤，看看是否有表扫描（Full Table Scan）、索引使用不当、或者不合理的连接顺序等问题。例如：

```sql
EXPLAIN SELECT * FROM orders WHERE customer_id = 123;
```

### 2. **检查索引**

- 检查相关表的索引情况，确认查询条件中的列是否有合适的索引。
- 检查索引是否被正确使用，尤其是在 WHERE、JOIN、ORDER BY 和 GROUP BY 子句中。

```sql
SHOW INDEX FROM orders;
```

### 3. **分析表统计信息**

- 确保表的统计信息（Statistics）是最新的。可以通过运行 `ANALYZE TABLE` 或者数据库自动统计功能来更新统计信息。数据库通常根据这些统计信息来决定执行计划。

```sql
ANALYZE TABLE orders;
```

### 4. **优化查询**

- **简化查询**：尝试简化查询，拆分复杂的 SQL，或者分步执行以减少开销。
- **避免子查询**：有时将子查询改写为 JOIN 或者使用临时表会提高性能。
- **减少 SELECT \* 的使用**：仅选择需要的列，而不是使用 `SELECT *`。
- **WHERE 条件优化**：确保 WHERE 子句尽可能早地过滤数据，减少参与后续操作的数据量。

### 5. **检查数据库服务器资源**

- **检查系统资源**：CPU、内存、磁盘 I/O 和网络带宽是否存在瓶颈。

```sql
SHOW FULL PROCESSLIST;
```

- **锁争用**：查看是否有锁争用情况，可能导致 SQL 等待资源。
- **慢查询日志**：检查慢查询日志，分析是否存在其他系统级的瓶颈或数据库配置问题。

```sql
SET GLOBAL slow_query_log = 'ON';
SET GLOBAL long_query_time = 1; -- 记录执行时间超过1秒的查询
SHOW VARIABLES LIKE 'slow_query_log_file'; --查看慢查询日志的位置
```

### 6. **调整数据库配置**

- **缓冲区大小**：调整数据库的缓存和缓冲区大小，如 InnoDB 的 buffer pool size，PostgreSQL 的 shared buffers 等。
- **并发连接数**：检查并发连接数设置是否合理。
- **临时表空间**：增加临时表空间的大小或者将其移动到更快的存储设备。

### 7. **缓存和持久化策略**

- 可以利用缓存机制（如 Redis、Memcached）缓存频繁访问的数据，减少数据库的负担。
- 考虑使用物化视图（Materialized View）来存储复杂查询的结果，减少每次查询的计算量。



## 2、MySql有哪些索引类型？

**1. B-Tree 索引**：

- **描述**：这是 MySQL 中最常见的索引类型。大多数 MySQL 存储引擎（如 InnoDB 和 MyISAM）都支持 B-Tree 索引。
- **应用场景**：适用于全键值、键值范围查找和前缀查找。对于`ORDER BY`、`GROUP BY`和范围查询（如`BETWEEN`、`>`, `<`等）非常高效。
- **前缀索引 (Prefix Index)**：
  - **描述**：可以对字符串列的前几个字符创建索引，而不是整个字符串。减少索引大小，节省空间。
  - **应用场景**：适用于需要索引长字符串但不需要完整索引的场景，例如只需索引前几字符的URL。
- **复合索引 (Composite Index)**：
  - **描述**：复合索引是将多个列组合在一起形成的索引。
  - **应用场景**：当查询条件涉及多个列时，使用复合索引可以提高查询效率。复合索引中的列顺序非常重要，查询必须符合索引的列顺序才能充分利用索引。

**2. Hash 索引**：

- **描述**：使用哈希表实现的索引，只能用于精确查找，不支持范围查找。
- **应用场景**：适用于精确匹配的查询。典型的应用场景是 `MEMORY` 存储引擎的表，或者 InnoDB 引擎的唯一哈希索引（adaptive hash index）。

**3. 全文索引 (Full-Text Index)**：

- **描述**：全文索引用于对文本字段进行全文搜索，在 MySQL 中支持 InnoDB 和 MyISAM 引擎。
- **应用场景**：适用于对大文本字段进行关键词查询，像`MATCH...AGAINST`语句中的全文搜索。

**4. 空间索引 (Spatial Index)**：

- **描述**：空间索引用于处理GIS（地理信息系统）数据的存储和查询，采用 R-Tree 数据结构。
- **应用场景**：适用于 MySQL 中的`Geometry`类型数据，用于处理地理数据的空间查询。





## 3、MySQL有哪几个数据库引擎，它们的主要区别是什么？

### 1. **InnoDB**

- **事务支持**：InnoDB 支持 ACID 事务，因此能够确保数据的可靠性和一致性。支持回滚、提交和崩溃恢复功能。
- **外键支持**：InnoDB 是 MySQL 中唯一支持外键约束的引擎，允许定义外键关系来保证数据完整性。
- **锁机制**：使用行级锁（Row-level locking），因此在高并发环境下表现良好，减少了锁冲突。
- **崩溃恢复**：InnoDB 使用日志文件来记录未完成的事务，以便在数据库崩溃时能够恢复。
- **适用场景**：适用于需要高可靠性、高并发写操作和复杂查询的应用，如金融系统、电商平台等。

### 2. **MyISAM**

- **事务支持**：MyISAM 不支持事务处理，因此不适用于需要数据一致性的关键应用。

- **外键支持**：不支持外键约束，数据完整性需要通过应用程序层来维护。

- **锁机制**：使用表级锁（Table-level locking），在写入操作较多的环境下，可能会导致较高的锁争用。

- **速度**：在读操作频繁、数据不经常更改的场景下，MyISAM 的查询速度比 InnoDB 快。

  - MyISAM 在读操作频繁、数据不经常更改的场景下查询速度比 InnoDB 快的主要原因可以归结为以下几点：

    #### 1. **表级锁（Table-level Locking）**

    MyISAM 使用表级锁定机制，这意味着当进行读或写操作时，整个表会被锁定。这种锁定机制在读操作频繁且数据较少更新的场景下能够非常高效，因为：

    - **锁开销低**：相比 InnoDB 的行级锁，表级锁的开销更低。当只有读操作时，MyISAM 的锁定机制非常简单，因此性能较高。
    - **并发性**：虽然表级锁在写操作频繁时会影响并发性，但在大量读操作的场景下，不存在锁争用的情况，查询性能优异。

    #### 2. **存储结构简单**

    MyISAM 的存储结构相对 InnoDB 更为简单：

    - **数据和索引存储**：MyISAM 将数据和索引分别存储在不同的文件中，这样的结构使得在执行纯粹的读取操作时，可以更快速地访问数据。
    - **不支持事务**：MyISAM 不支持事务处理，这意味着不需要维护事务日志或处理回滚和提交操作，这减少了磁盘 I/O 和 CPU 开销。

    3. **较小的存储开销**

    MyISAM 相比 InnoDB，数据存储效率较高，占用的磁盘空间更小。这种紧凑的存储方式意味着在相同硬件条件下，MyISAM 可以加载更多的数据到内存中，从而提高查询速度。

    #### 4. **全文索引（Full-Text Search）**

    MyISAM 支持内建的全文索引，特别适合文本搜索的场景。在涉及大量文本数据的查询中，MyISAM 的全文索引可以显著提高查询性能，而 InnoDB 直到后来的版本才引入了全文索引功能。

    #### 5. **无外键约束**

    MyISAM 不支持外键约束，减少了维护关系完整性的开销。在没有外键关系或关系维护由应用程序管理的情况下，MyISAM 不需要进行额外的关系完整性检查，因此执行查询的速度更快。

- **适用场景**：适用于读操作较多的应用，如数据仓库、日志记录等。

### 3. **Memory**

- **存储位置**：数据存储在内存中，因此读写速度非常快，但在服务器关闭时数据会丢失。
- **锁机制**：使用表级锁。
- **数据持久性**：不提供数据持久化，适用于需要高速访问临时数据的场景。
- **适用场景**：适用于需要快速访问临时数据的场景，如临时表、缓存等。

### 4. **CSV**

- **存储格式**：数据以 CSV 文件的形式存储在磁盘上，每个表对应一个 CSV 文件。
- **速度**：由于没有索引支持，数据查询速度较慢。
- **兼容性**：适用于需要与外部程序（如 Excel）交换数据的场景。
- **适用场景**：适用于需要简单数据导入/导出功能的应用场景。

### 5. **其他引擎**

- **Aria**：类似 MyISAM，但更为可靠，支持崩溃恢复，通常用于 MariaDB。
- **Federated**：用于访问远程 MySQL 数据库中的表，通过 MySQL 服务器之间的连接，实现跨服务器的分布式数据库。
- **Archive**：用于存储大量的归档数据，主要用于插入和查询操作，不支持索引，适用于存储日志数据。

### 总结

- **InnoDB** 是默认且最常用的引擎，适用于绝大多数应用场景，尤其是那些需要事务支持和数据一致性的场景。
- **MyISAM** 适用于读操作频繁且不要求事务处理的应用。
- **Memory** 适用于需要快速访问的临时数据。
- **CSV** 适用于与外部系统进行数据交换的场景。



## 4、悲观锁和乐观锁的区别？

### 1. 悲观锁（Pessimistic Lock）

- **实现方式：** 在对数据进行读或写之前，先对数据进行加锁，阻止其他事务或线程对数据的访问，直到当前操作完成并释放锁。
- **场景：** 悲观锁通常用于写操作多、冲突概率高的场景。典型的例子包括数据库中的行锁（Row Lock），在事务开始时对要访问的行加锁，直到事务结束才释放。
- **优点：** 确保数据的一致性，避免了冲突和死锁（通过严格控制锁的顺序）。
- **缺点：** 可能导致性能瓶颈，因为其他操作可能会因为锁的存在而被阻塞，尤其是在冲突很少发生的情况下，这种锁机制会带来不必要的开销。

### 2. 乐观锁（Optimistic Lock）

- **实现方式：** 在更新数据时，不直接加锁，而是在提交时检查数据是否被其他事务或线程修改过。通常通过“版本号”或“时间戳”等机制实现。如果发现数据已经被修改，则操作失败，重新尝试。
- **场景：** 乐观锁通常用于读操作多、冲突概率低的场景。例如，在版本控制系统或数据库的CAS（Compare and Swap）操作中，常用乐观锁来确保数据的一致性。
- **优点：** 不需要加锁，大大减少了因锁引起的性能开销，更适合读多写少的场景。
- **缺点：** 如果冲突频繁，乐观锁的重试机制会导致性能下降，并增加系统开销。



## 5、Redis为什么快？

首先，需要明确，Redis只有`redis-server`是单线程的，指所有的命令处理流程在一个线程中处理。

1. Redis是内存数据库，所有操作都是基于内存的， 不是CPU密集型的。
2. 数据结构高效，不同的对象类型有不同的具体实现。
   - string：
     - int
     - raw
     - embstr
   - list: quicklist, 节点采用ziplist
   - hash:
     - ziplist
     - dict
   - set:
     - intset
     - dict
   - zset:
     - ziplist
     - **skiplist**
3. 如果是多线程，那么就需要加锁，Redis中sds, list, hash, set, zset都有多种不同的实现，因此锁的粒度不好控制同时会导致CPU频繁的上下文切换。
4. 对于网络连接，实际上采用的是Reactor网络模型，多路IO复用，非阻塞IO。
5. 单线程所作的优化（**耗时阻塞的操作，另起线程处理**）：
   - 异步关闭大文件 `bio-close-file`
   - 异步释放大内存 `bio-lasy-free`
   - 异步AOF刷盘 `bio-aof-fasync`
   - 内存池分配 `jemalloc-bg-threads`
   - IO多线程 `io-threads` read/write/decode/encode
   - 将大操作拆分成小操作
     - 渐进式rehash： ①分散在每一步操作中，移动一个 ②空闲时，rehash 1ms
   - 根据对象选择不同的数据结构
     - 根据节点的数量动态选择数据结构
     - 在时间和空间上进行均衡



## 6、Redis如何保证断电后数据不会丢失？如何做到数据高可用且避免不一致问题？

### 1. 数据持久化

Redis 提供了两种持久化方式来保证断电后数据不会丢失：

#### 1.1. RDB（Redis Database Backup）

- **机制：** Redis会在特定的时间间隔内将内存中的数据快照保存到磁盘中，生成一个 `.rdb` 文件。这个文件包含了某个时间点的数据快照。
- **优点：** RDB 生成的文件非常紧凑，适合备份和恢复时使用，恢复速度较快。
- **缺点：** 因为 RDB 是定时保存数据快照，所以在系统崩溃时，可能会丢失最近一次快照后的所有数据。

#### 1.2. AOF（Append Only File）

- **机制：** AOF 以日志的形式记录每个写操作，并将这些操作依次追加到文件中。Redis 提供了三种不同的同步策略：每次写操作后同步（appendfsync always）、每秒同步一次（appendfsync everysec）、从不同步（appendfsync no）。
- **优点：** AOF 提供了更高的数据安全性，因为它可以记录每个写操作，可以避免数据丢失。
- **缺点：** AOF 文件通常比 RDB 文件大，而且恢复速度相对较慢。
- **AOF 重写机制：** 由于 AOF 文件不断增长，Redis 提供了 AOF 重写机制，定期将 AOF 文件压缩为一个新的文件，以减少文件大小和恢复时间。

### 2. 数据高可用性和一致性

为了实现数据的高可用性并避免不一致问题，Redis通常采用以下策略：

#### 2.1. 主从复制（Replication）

- **机制：** Redis 支持主从复制，一个 Redis 服务器（主节点）可以有多个从节点。主节点处理写操作，并将数据同步到从节点。从节点可以处理读请求，这样就可以提高读性能。
- **数据同步：** 初次复制时，从节点会进行一次全量复制，之后主节点只将写操作的命令流发送给从节点，实现增量同步。
- **高可用性：** 如果主节点故障，可以手动或通过工具将某个从节点提升为新的主节点，从而继续提供服务。

#### 2.2. 哨兵模式（Sentinel）

- **机制：** Redis 哨兵（Sentinel）是一个用于监控 Redis 主从实例的高可用性解决方案。Sentinel 可以自动执行主从切换，当主节点不可用时，会自动将一个从节点提升为主节点，并通知客户端更新连接信息。
- **优势：** Sentinel 提供了自动故障转移、主从切换、通知等功能，确保 Redis 集群的高可用性。

#### 2.3. Redis 集群（Cluster）

- **机制：** Redis 集群通过数据分片（Sharding）来将数据分布在多个节点上。每个节点负责存储一部分数据，并且每个节点都有一到多个从节点来保证高可用性。
- **一致性保障：** Redis 集群使用一致性哈希算法来分配数据，并且使用 Gossip 协议来节点间交换状态信息。为了防止脑裂现象，集群中需要多数派（majority）投票才能进行主从切换，从而避免数据不一致。
- **故障转移：** 如果某个主节点失败，集群会自动选举其中一个从节点作为新的主节点，从而实现自动故障恢复。





## 7、缓存雪崩、击穿、穿透和解决办法？

### 缓存穿透（Cache Penetration）：Redis和MySQL中都没有

> 缓存穿透是指在缓存系统中，某些查询由于没有命中缓存而直接访问底层数据库，导致数据库压力增大的问题。具体来说，缓存穿透发生在当请求的数据在缓存和数据库中都不存在时，所有请求都会穿透缓存直接访问数据库，从而使得缓存失去了其减少数据库访问压力的作用。

1. **缓存空结果**：如果查询一个数据时发现数据不存在，可以将这个空结果也缓存起来，设置一个短的过期时间（如几分钟）。这样在这个过期时间内，再次查询同样的数据会直接返回缓存的空结果，避免频繁访问数据库。
2. **使用布隆过滤器**：布隆过滤器是一种概率型数据结构，用于快速判断一个元素是否在一个集合中。**可以在缓存层之前增加布隆过滤器(服务器可能有多个)**，所有查询先经过布隆过滤器，如果判断该数据一定不存在，则直接返回空结果而不访问数据库；如果布隆过滤器判断该数据可能存在，再继续访问缓存或数据库。***缺点：只能增加，不能删除***
3. **参数校验和限流**：对传入的查询参数进行严格校验，过滤掉非法或明显错误的请求，从源头上减少无效查询。此外，可以对频繁访问的请求进行限流，避免短时间内大量请求穿透缓存。





### 缓存击穿（Cache Breakdown）：Redis无，MySQL有，大量***并发连接***请求

1. **热点数据永不过期**：对某些特别重要和访问频率非常高的数据，可以设置为永久缓存，不让其过期。这可以避免缓存击穿的问题，但需要定期手动更新缓存，以确保数据的一致性。
2. **互斥锁（Mutex）**：在缓存失效时，通过加锁机制控制只有一个线程可以查询底层数据库并更新缓存，其余线程等待缓存更新完毕再获取数据。这种方法可以通过分布式锁（如Redis分布式锁）来实现。
3. **双重缓存**：使用双缓存机制，设置两个缓存区域A和B，当A区数据过期时，访问B区的数据，同时异步更新A区的数据。这样即使A区过期，也能从B区获取到稍旧的数据，从而避免了缓存击穿。
4. **请求合并**：在高并发情况下，可以将多个相同的请求合并为一个请求处理，避免多个线程同时去数据库查询相同的数据。这可以通过消息队列或批处理的方式来实现。



### 缓存雪崩（Cache Avalanche）：同一时间大量缓存数据***集中失效***，导致大量请求直接访问数据库

1. **缓存失效时间加随机值**：设置缓存失效时间时，加上一个随机的偏移量，避免大量缓存同时过期。比如，如果默认过期时间是1小时，可以在此基础上加上一个0-10分钟的随机时间。
2. **分布式缓存**：使用分布式缓存系统，如Redis集群，将缓存数据分散在多个节点上。这样，即使某些节点的缓存失效，其他节点的缓存仍然可用，从而分散压力。
3. **缓存预热**：在系统启动或数据更新时，提前将热点数据加载到缓存中，避免在系统运行期间发生缓存雪崩。可以通过定时任务或脚本来实现缓存预热。
4. **异步更新缓存**：当缓存失效时，通过异步方式更新缓存，避免请求线程等待缓存更新完成。在请求到达时，如果发现缓存失效，可以立即返回旧缓存数据，并异步更新缓存。

**缓存击穿** 关注的是缓存数据的热点问题，主要是高并发访问一个失效的缓存。

**缓存穿透** 关注的是缓存和数据库中都不存在的数据频繁查询问题。

**缓存雪崩** 关注的是大量缓存同时失效或缓存服务不可用导致数据库压力骤增的问题。



8、简要介绍一下gRPC？

## 9、gRPC的文件是什么后缀(格式)

`.proto`



## 10、gRPC的代码格式是什么样的？支持定义默认值吗？定义数组的关键字是什么？

接口和消息的定义通常使用 Protocol Buffers (Protobuf) 来进行编写。

### 1. gRPC 的代码格式

gRPC 的服务和消息通常在 `.proto` 文件中定义。以下是一个示例：

```protobuf
syntax = "proto3";

package example;

service MyService {
  // 定义一个 RPC 方法
  rpc MyMethod (MyRequest) returns (MyResponse) {}
}

message MyRequest {
  string name = 1;
  int32 age = 2;
  repeated string hobbies = 3;
}

message MyResponse {
  string message = 1;
}
```

- `syntax = "proto3";`：指定使用 Protobuf 3 的语法。
- `package example;`：定义 Protobuf 的包名。
- `service MyService`：定义一个 gRPC 服务，包含一个或多个 RPC 方法。
- `rpc MyMethod`：定义一个 RPC 方法，接收 `MyRequest` 消息，返回 `MyResponse` 消息。
- `message MyRequest` 和 `message MyResponse`：定义消息类型，类似于结构体或类。

### 2. 默认值

在 Protobuf 3 中，**不支持显式定义默认值**。Protobuf 3 自动为所有基本类型提供默认值：

- `string` 默认是空字符串 `""`。
- `int32`, `int64`, `uint32`, `uint64` 默认是 `0`。
- `bool` 默认是 `false`。
- `enum` 默认是枚举的第一个值。

如果字段未被显式设置，它将使用这些默认值。

例如：

```protobuf
message MyRequest {
  string name = 1;  // 默认值是 ""
  int32 age = 2;    // 默认值是 0
}
```

### 3. 定义数组的关键字

在 Protobuf 中，使用 `repeated` 关键字来定义一个字段为数组（或列表）。例如：

```protobuf
message MyRequest {
  repeated string hobbies = 3;
}
```

在这个示例中，`hobbies` 是一个字符串数组，可以包含零个或多个元素。





## 11、除了gRPC你还用过哪些RPC技术栈，你所知道的RPC框架有哪些？

### 1. **Thrift**

- **概述**：Apache Thrift是一个可伸缩的跨语言服务开发框架。它最初由Facebook开发，用于在不同语言之间进行高效的RPC调用。
- **支持语言**：C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Node.js等。
- **特点**：Thrift通过IDL（接口描述语言）定义服务和数据类型，并自动生成客户端和服务端的代码。它支持二进制和压缩的传输协议，使其在高性能要求的场景中表现出色。

### 2. bRPC (Baidu RPC)

+ **概述**：bRPC 是由百度开发的一个开源高性能 RPC 框架，最早应用于百度内部的分布式系统中。bRPC 是基于 C++ 实现的，旨在提供一个高效、稳定、可扩展的 RPC 解决方案，特别适合构建大规模分布式系统。

#### 主要特点

1. **高性能**：bRPC 经过大量的性能优化，在高并发场景下表现优异，适合大规模分布式系统中的高吞吐量需求。
2. **稳定性**：bRPC 在百度内部经过多年大规模应用和优化，具有高度的稳定性，支持长时间、大规模的生产环境运行。
3. **丰富的功能**：
   - 支持多种协议：bRPC 支持多种通信协议，如 HTTP、Protobuf、Streaming RPC 等。
   - 完整的服务治理能力：包括负载均衡、超时控制、重试机制、流量控制等功能。
   - 提供强大的监控能力：bRPC 内置了丰富的监控指标，可以方便地集成到监控系统中。
4. **易用性**：bRPC 提供了简洁易用的接口，开发者可以快速上手，并且支持与 Protobuf 等常用的序列化协议结合。
5. **扩展性**：bRPC 的设计非常灵活，支持插件式的扩展，开发者可以根据需要定制协议、负载均衡策略等。

### sRPC (Sohu RPC)

+ **概述**：sRPC 是由搜狐畅游开发的一款高性能、可扩展的 RPC 框架。sRPC 同样是基于 C++ 实现的，并在设计时参考了 gRPC 和 bRPC 的一些优秀理念，目标是在性能、功能和易用性之间取得平衡。

#### 主要特点

1. **高性能**：sRPC 也专注于高性能的远程过程调用，在搜狐内部被广泛应用于高并发的游戏和互联网服务中。
2. **支持多种协议**：
   - sRPC 支持多种序列化协议，如 Protobuf、JSON、Thrift 等，能够与多种不同的服务通信。
   - 同时支持 HTTP、WebSocket 等多种传输协议，适合不同类型的服务场景。
3. **丰富的功能**：
   - sRPC 提供了负载均衡、流量控制、熔断器等服务治理功能。
   - 支持多种通信模式，包括同步、异步、流式 RPC 等，满足不同的业务需求。
4. **插件机制**：sRPC 采用模块化设计，支持通过插件扩展功能，如自定义协议、序列化方式等。
5. **易用性**：sRPC 提供了良好的文档和工具支持，使得开发者能够快速构建和部署分布式服务。



## 12、QUIC相对于HTTP2有哪些重大变化？

HTTP/2 通过头部压缩、二进制编码、多路复用、服务器推送等新特性大幅度提升了 HTTP/1.1 的性能，而美中不足的是 HTTP/2 协议是基于 TCP 实现的，于是存在的缺陷有三个。

- **队头阻塞**，HTTP/2 多个请求跑在一个 TCP 连接中，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经接收了，应用层也无法从内核中读取到这部分数据，从 HTTP 视角看，就是多个请求被阻塞了；
- **TCP 和 TLS 握手时延**，TCP三次握手和 TLS 四次握手，共有 3个RTT 的时延；
- **连接迁移需要重新连接**，移动设备从 4G 网络环境切换到 WIFI 时，由于 TCP 是基于四元组来确认一条 TCP 连接的，那么网络环境变化后，就会导致 IP 地址或端口变化，于是 TCP 只能断开连接，然后再重新建立连接，切换网络环境的成本高；

HTTP/3 就将传输层从 TCP 替换成了 UDP，并在 UDP 协议上开发了 QUIC 协议，来保证数据的可靠传输。

QUIC 协议的特点：

- **无队头阻塞**，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，也不会有底层协议限制，某个流发生丢包了，只会影响该流，其他流不受影响；
- **建立连接速度快**，因为 QUIC 内部包含 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与 TLS 密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。
- **连接迁移**，QUIC 协议没有用四元组的方式来“绑定”连接，而是通过「连接 ID」来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本；



## 13、slice的底层实现？

切片在Go语言中的底层结构定义如下：

```go
type SliceHeader struct {
    Data uintptr
    Len  int
    Cap  int
}
```

- **Data（指针）**：指向底层数组的第一个元素的指针。
- **Len（长度）**：切片的长度，表示切片中实际包含的元素个数。
- **Cap（容量）**：切片的容量，表示从切片起始位置到底层数组末尾的位置之间可以容纳的元素个数。



## 14、slice和数组的区别？

切片并不直接存储数据，而是引用了底层的数组。当你创建一个切片时，它实际上是对底层数组的一个引用。这个引用通过 `Data` 字段来指向底层数组中的某个位置，而切片的 `Len` 和 `Cap` 决定了它能访问数组中的哪些元素。

```go
arr := [5]int{1, 2, 3, 4, 5}
sli := arr[1:4]  // 创建一个切片，引用数组的第2到第4个元素
```

在上面的例子中，`sli` 是一个切片，它的 `Data` 指针指向 `arr[1]`，`Len` 为 3（即从 `arr[1]` 到 `arr[3]`），`Cap` 为 4（即从 `arr[1]` 到 `arr[4]`）。



## 15、slice的扩容机制？

### 扩容机制的规则

1. **容量小于1024**：如果扩容前切片的容量小于1024，当切片容量不足时，Go会将切片容量翻倍（即新容量为原容量的2倍）。
2. **容量大于等于1024**：如果扩容前切片的容量大于等于1024，当切片容量不足时，Go会按照1.25倍的比例扩容（即新容量为原容量的1.25倍）。不过，这个倍数并不是固定的，而是根据具体实现和需求可能会有所调整。

### 扩容的具体过程

1. **检查容量是否足够**：当使用 `append` 向切片中添加元素时，首先会检查现有的容量是否足够。如果容量足够，则直接将新元素添加到切片中。
2. **分配新数组**：如果现有的容量不足以容纳新元素，Go 会根据上述规则计算新的容量，并分配一个新的底层数组，这个新数组的容量比旧的数组更大。
3. **数据迁移**：Go 会将旧切片的数据复制到新分配的数组中。
4. **返回新的切片**：最后，`append` 会返回一个引用新数组的切片。这个新切片包含了旧切片的所有数据以及新添加的元素。



## 16、slice是线程安全的吗？

在Go语言中，**切片（slice）本身不是线程安全的**。这意味着，如果多个goroutine并发地对同一个切片进行读写操作，而没有适当的同步机制（如使用互斥锁），则可能会导致数据竞争（data race），从而引发未定义的行为。

### 数据竞争的风险

切片在多个goroutine中并发访问时，可能会发生以下问题：

1. **读写冲突**：一个goroutine在读取切片的数据时，另一个goroutine可能同时对切片进行写操作。这样会导致读取的数据不一致，甚至程序崩溃。
2. **扩容问题**：当对切片执行追加操作（`append`）时，可能会触发切片的扩容机制。扩容时，切片会分配新的底层数组并复制数据。如果多个goroutine同时触发扩容，可能会导致底层数组被覆盖或数据丢失。

### 解决方法

如果你需要在多个goroutine中并发地操作同一个切片，通常有几种方法可以确保线程安全：

1. **使用互斥锁（Mutex）**： 通过使用 `sync.Mutex` 或 `sync.RWMutex`，可以确保在同一时间只有一个goroutine可以修改切片。互斥锁提供了一种简单且直接的方法来保护切片的并发访问。
2. **使用通道（Channels）**： Go中的通道可以用来在多个goroutine之间传递数据，避免直接对共享数据结构的并发访问。可以将所有对切片的操作封装在一个单独的goroutine中，并通过通道与其他goroutine通信。
3. **使用线程安全的数据结构**： 有些情况下，可以考虑使用像 `sync.Map` 这样内置的线程安全数据结构，尽管它是为map设计的，但根据需求可以封装类似的逻辑来使用。
4. **复制切片**： 在某些情况下，特别是只读操作时，可以为每个goroutine创建切片的一个副本，这样就不会发生数据竞争问题。但这适用于数据量较小的场景，因为复制操作可能会增加内存开销。



## 17、map是线程安全的吗？如何实现一个线程安全的map？

在Go语言中，**map 本身不是线程安全的**。这意味着，如果在多个goroutine中并发地对同一个`map`进行读写操作，而没有适当的同步机制，可能会导致数据竞争（data race）和未定义的行为，甚至程序崩溃。

### 线程不安全的原因

`map` 的底层实现并不包含任何同步机制，因此在并发环境中，多个goroutine同时进行读写操作时，可能会导致以下问题：

1. **数据竞争**：同时读取和写入`map`可能会导致读取的数据不一致，或写入过程中丢失数据。
2. **程序崩溃**：在并发写入`map`的情况下，Go的运行时可能会抛出一个 `fatal error: concurrent map writes`，直接导致程序崩溃。

### 如何实现一个线程安全的 `map`

为了在并发环境中安全地使用`map`，你需要使用同步机制。下面介绍几种常见的方法来实现线程安全的`map`。

#### 1. 使用 `sync.Mutex`

最简单的方法是使用互斥锁（`sync.Mutex`）来保护对`map`的访问。通过加锁和解锁，确保在同一时刻只有一个goroutine可以操作`map`。

#### 2. 使用 `sync.RWMutex`

`sync.RWMutex` 是一个读写锁，它允许多个读操作同时进行，但在写操作进行时会锁定所有的读写操作。如果你的程序中读操作比写操作多，可以考虑使用 `sync.RWMutex` 来提高性能。

#### 3. 使用 `sync.Map`

Go标准库提供了一个内置的线程安全的 `map` 实现，叫做 `sync.Map`。`sync.Map` 提供了一些简单的接口，如 `Store`、`Load`、`LoadOrStore` 和 `Delete`，并且可以安全地在多个goroutine中并发使用。

`sync.Map` 是为了高并发场景设计的，特别是需要频繁读写的情况下。它内部使用了一些优化来减少锁争用，从而提高性能。



## 18、channel的底层实现原理？

### `channel` 的基本结构

`channel` 在Go语言的底层表示为一个结构体。虽然具体的实现可能会随着Go版本的更新有所变化，但基本结构和概念大致如下：

```go
type hchan struct {
    qcount   uint           // 队列中的数据元素个数
    dataqsiz uint           // 循环队列的大小（缓冲区的大小）
    buf      unsafe.Pointer // 指向底层数组的指针（存放数据的缓冲区）
    elemsize uint16         // 单个元素的大小
    closed   uint32         // channel是否已关闭
    elemtype *_type         // 元素的类型
    sendx    uint           // 发送操作的下标
    recvx    uint           // 接收操作的下标
    recvq    waitq          // 等待接收的goroutine队列
    sendq    waitq          // 等待发送的goroutine队列
    lock     mutex          // 保护channel的互斥锁
}
```

### 关键字段解释

- **qcount**：当前队列中的元素个数。
- **dataqsiz**：缓冲区的大小，即channel的容量。
- **buf**：指向底层存储元素的数组（循环队列）的指针。如果是无缓冲的`channel`，这个指针可能为空。
- **elemsize**：每个元素的大小，以字节为单位。
- **closed**：表示`channel`是否已经关闭。
- **elemtype**：存储在`channel`中的元素类型。
- **sendx** 和 **recvx**：分别表示发送和接收操作的下标，用于在循环队列中确定数据存储的位置。
- **recvq** 和 **sendq**：当`channel`无法立即进行发送或接收时，会将对应的goroutine放入这两个等待队列中。
- **lock**：用于保护`channel`的互斥锁，确保并发操作的安全。



## 19、channel发送数据和接收数据的过程？

### `channel` 的工作流程

#### 1. 发送数据

当一个goroutine向`channel`发送数据时，`channel`的底层会检查以下几种情况：

- **缓冲区未满**：如果`channel`有缓冲区且未满，数据会被直接写入缓冲区，并更新`sendx`（发送下标）。
- **缓冲区已满或无缓冲**：如果`channel`的缓冲区已满，或者是无缓冲的`channel`，当前的goroutine将被阻塞，并加入到`sendq`等待队列中，直到有空间可用或有接收方准备好接收数据。
- **接收队列不为空**：如果有等待接收的goroutine（`recvq`非空），数据会直接发送给接收方的goroutine，接收方被唤醒。

#### 2. 接收数据

当一个goroutine从`channel`接收数据时，`channel`的底层会进行以下操作：

- **缓冲区不为空**：如果`channel`有缓冲区且不为空，数据会直接从缓冲区读取，`recvx`（接收下标）更新，返回数据给接收方。
- **缓冲区为空或无缓冲**：如果缓冲区为空或者是无缓冲的`channel`，当前的goroutine会被阻塞，并加入到`recvq`等待队列中，直到有数据可接收。
- **发送队列不为空**：如果有等待发送的goroutine（`sendq`非空），会直接从发送队列中取出数据，传递给接收方，发送方被唤醒。

#### 3. `channel` 的关闭

当`channel`被关闭时，会做以下处理：

- **所有阻塞在接收操作的goroutine**：这些goroutine将会被唤醒，并且接收到一个零值和一个表示`channel`已关闭的状态。
- **阻塞在发送操作的goroutine**：这些goroutine将会panic，因为无法再向已关闭的`channel`发送数据。

#### 4. 并发安全性

`channel`通过`mutex`来保护所有对它的操作，确保在多goroutine环境下的并发安全性。`mutex`确保在任何时候，只有一个goroutine可以对`channel`进行修改操作，从而避免数据竞争。



## 20、defer的作用？

**延迟执行**： `defer` 后面的函数或表达式会在当前函数执行完毕后才执行，哪怕函数中间发生了 `panic` 或提前返回。

**栈式调用**： 如果有多个 `defer` 语句，它们会按照后进先出的顺序执行（类似于栈结构）。最后一个 `defer` 语句会最先执行。

**简化资源管理**： `defer` 常用于关闭文件、释放锁、关闭网络连接等操作。将这些清理操作放在 `defer` 中，能确保无论函数正常返回还是异常退出，资源都能得到正确的释放。



## 21、defer的底层原理？

### 1. **编译器处理 defer 语句**：

在函数执行时，每遇到一个 `defer` 语句，Go 编译器会将 `defer` 后面的函数调用包装成一个**匿名函数**，并将其作为一个延迟执行的任务放到一个栈中。这个栈是在函数的运行时栈帧（stack frame）内维护的。

### 2. **延迟执行的函数入栈**：

每当遇到 `defer` 语句时，编译器会生成代码，将 `defer` 后面的函数调用推入栈中（存储在栈帧中）。这些调用会以逆序（后进先出）执行。因此，最先定义的 `defer` 语句会在最后执行。

### 3. **函数返回时的栈展开**：

当包含 `defer` 语句的函数即将返回时（无论是正常返回还是通过 `panic` 中止），Go 运行时会按照栈的后进先出顺序，依次执行所有已登记的 `defer` 函数。这个过程被称为栈展开（stack unwinding）。

### 4. **传递参数的时机**：

`defer` 的函数参数在 `defer` 语句执行时就已经被求值并拷贝，而不是在实际执行 `defer` 函数时才求值。这个特性在有闭包时尤其重要。

### 5. **在函数栈中的表示**：

在函数栈帧中，每个 `defer` 调用都以一个链表的形式存储。这种链表结构在函数返回时被遍历并执行。每个节点包含了被延迟执行的函数信息以及相关的参数。



## 22、如果在匿名函数内panic了，在匿名函数外的defer是否会触发panic-recover？反之在匿名函数外触发panic，是否会触发匿名函数内的panic-recover？

### 1. **在匿名函数内 panic，匿名函数外的 defer 是否会触发 recover？**

假设在匿名函数内触发了 `panic`，匿名函数外有一个 `defer`，并且这个 `defer` 中调用了 `recover` 函数。那么这个 `recover` 会触发并捕获 `panic`。具体情况如下：

- 当匿名函数内发生 `panic` 时，`panic` 会沿着调用栈向上传播。
- 如果在调用匿名函数的外层函数中有一个 `defer`，并且 `defer` 中调用了 `recover`，那么这个 `recover` 可以捕获到这个 `panic`。
- 这意味着即使 `panic` 是在匿名函数中发生的，它仍然可以被外层函数中的 `recover` 捕获。

### 2. **在匿名函数外触发 panic，匿名函数内的 defer 是否会触发 recover？**

如果在匿名函数外发生 `panic`，匿名函数内的 `defer` 中的 `recover` 是无法捕获到这个 `panic` 的。原因如下：

- `panic` 沿着调用栈向上传播。
- 匿名函数内的 `recover` 只能捕获匿名函数内发生的 `panic`，它无法捕获在外层函数中发生的 `panic`。



## 23、简单介绍下GMP模型？

`Golang`的调度器采用`M:N`调度模型，其中M代表用户级别的线程(也就是`goroutine`)，而N代表的事内核级别的线程。`Go`调度器的主要任务就是N个OS线程上调度M个`goroutine`。这种模型允许在少量的OS线程上运行大量的`goroutine`。

`Go`调度器使用了三种队列来管理`goroutine`

1. **全局队列(Global Queue)**：此队列中包含了所有刚创建的`goroutine`。
2. **本地队列(Local Queue)**：每个P(Processor，处理器)都有一个本地队列，P会有限从本地队列中取出`goroutine`来执行。
3. **网络轮循器(Netpoller)**：此队列中包含了所有在等待网络时间(如IO操作)的`goroutine`。当网络事件就绪时，对应的`goroutine`会被放入到全局队列中，等待被P取出。

`Go`的调度器采用了工作窃取(Work Stealing)和手动抢占(Preemption)的策略

- **工作窃取**：当一个P的本地队列中没有`goroutine`时，它会尝试从全局队列或其他P的本地队列中窃取`goroutine`来执行。
- **手动抢占**：为了防止一个`goroutine`长时间占用P而导致其他`goroutine`饿死，`Go`的调度器会定期地进行抢占操作。在`Go 1.14`之前，`Go`的调度器只在函数调用时才会进行抢占，从`Go 1.14`开始引入了异步抢占，即允许在任何安全点进行抢占。

这种调度模型和策略使得`Go`语言可以有效地利用硬件资源，处理大量的并发任务，同时也为复杂的并发编程提供了简介的语言级别的支持。



## 24、简单介绍一下Golang的GC

`Go`的`GC(Garbage Collection, 垃圾回收)`机制主要是用来自动释放不再被程序使用的内存，以防止内存泄漏。`Go`的垃圾回收是**并发**的，也就是说，它在主程序运行的同时进行垃圾回收。

### 1. 标记清除(Mark and Sweep)

`Go`的垃圾回收器主要使用的是标记清除算法。这个算法包含两个阶段：**标记阶段和清除阶段**。在标记阶段，垃圾回收期会从**根对象**(root object, 全局变量、栈上的变量等)开始，找出所有的可达的对象，并进行标记。在清除阶段，垃圾回收器会遍历堆中的所有对象，清除那些没有被标记的对象，也就是不可达的对象。

### 2. 并发执行(Concurrent Execution)

`Go`语言的的垃圾回收器并不会在运行时停止所有的用户级线程(即协程)。相反，它使用了一种称为三色标记清除(Tri-color Mark and Sweep)的算法，使得垃圾回收器可以在主程序运行的同时进行垃圾回收。在这个方法中，对象被分为三种颜色：

- **白色**：表示对象可能是垃圾，即未被确认是否可达。
- **灰色**：表示对象已被标记为存活，但其引用的对象还未完全检查。
- **黑色**：表示对象及其所有引用都已经被检查，确认为非垃圾。

这种方式可以减少程序的暂停时间，提高程序运行效率。

### 3. 写屏障(Write Barrier)

在并发标记阶段，由于用户程序和垃圾回收器是同时运行的， 用户程序可能会修改堆中的数据。为了在这种情况下保证垃圾回收的正确性，`Go`的垃圾回收器使用了写屏障技术。写屏障会在用户程序尝试写入一个指针时触发，更新垃圾回收器的标记信息。

### 4. 内存分配

`Go`的内存管理器与垃圾回收器紧密结合，使用了T型分配器（T型是针对不同大小的对象优化的内存分配策略）。小对象通常在连续的内存块中分配，这称为“span”。这种方式有助于提高内存分配的效率并减少碎片。

### 5. 垃圾回收调度(GC Pacing)

Go的垃圾回收周期由内存增长和分配活动触发。如果内存分配速度快于回收速度，回收器会更频繁地运行，以确保内存使用效率和程序性能。



代码手撕 25分钟

- lc206.反转链表

```go
/**
 * Definition for singly-linked list.
 * type ListNode struct {
 *     Val int
 *     Next *ListNode
 * }
 */
// 递归
func reverseList(head *ListNode) *ListNode {
    if head == nil || head.Next == nil {
        return head
    }

    newHead := reverseList(head.Next)
    head.Next.Next = head
    head.Next = nil

    return newHead
}
// 迭代
func reverseList(head *ListNode) *ListNode {
    if head == nil || head.Next == nil {
        return head
    }

    dummy := ListNode{-1, head}
    p := head.Next
    head.Next = nil
    for p != nil {
        next := p.Next
        p.Next = dummy.Next
        dummy.Next = p
        p = next
    }

    return dummy.Next
}
```



- lc1143.最长公共子序列 思路对了，中间过程也对 差输出部分没写出来...

```go
func longestCommonSubsequence(s string, t string) int {
    m, n := len(s), len(t)
    f := make([][]int, m + 1)
    for i := range f {
        f[i] = make([]int, n + 1)
    }

    for i := range s {
        for j := range t {
            if s[i] == t[j] {
                f[i+1][j+1] = f[i][j] + 1
            } else {
                f[i+1][j+1] = max(f[i][j], f[i+1][j], f[i][j+1])
            }
        }
    }

    return f[m][n]
}
```

