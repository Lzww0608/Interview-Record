# Golang|腾娱一面

## 1. 怎么保证消息发送给用户的时候不丢失，消息顺序如何保证

### 1. 保证消息不丢失

为了确保消息在发送给用户时不丢失，可以使用以下技术和策略：

#### 1.1 使用消息队列

- **消息队列（Message Queue）**：使用消息队列（如Kafka、RabbitMQ等）可以确保消息持久化到磁盘，防止消息丢失。如果消息处理失败，可以重新读取并处理。



#### 1.2 使用数据库持久化

- **持久化消息**：在将消息发送到用户之前，先将消息存储到数据库（如MySQL、PostgreSQL）中。这样即使系统崩溃，消息也不会丢失。



#### 1.3 确认机制

- **确认机制（Acknowledgement）**：发送消息后，要求接收方发送确认消息。如果未收到确认，可以重试发送。



### 2. 保证消息顺序

要保证消息的顺序，可以采用以下策略：

#### 2.1 单一消费者模式

- **单一消费者**：确保每个消息队列的主题（topic）只有一个消费者处理，保证消息按顺序处理。



#### 2.2 分区和键控分区

- **分区（Partitioning）**：使用分区键（partition key）将消息分配到特定分区中。同一分区内的消息会按顺序处理。例如，Kafka支持按分区键分区。



#### 2.3 事务机制

- **事务（Transactions）**：使用事务确保一组操作的原子性。如果系统支持事务，可以使用事务机制来保证消息的顺序性和一致性。



## 2. Kafka生产者的参数会设置哪一些？

**bootstrap.servers**: 用于连接Kafka集群的地址列表。格式为`host1:port1,host2:port2,...`。

**key.serializer**: 用于将生产者的键对象序列化为字节的类。例如，`org.apache.kafka.common.serialization.StringSerializer`。

**value.serializer**: 用于将生产者的值对象序列化为字节的类。例如，`org.apache.kafka.common.serialization.StringSerializer`。

**acks**: 用于指定生产者在收到来自服务器的响应之前的必要确认数。可以设置为`"all"`（等待所有副本确认）、`"1"`（等待领导者副本确认）或`"0"`（不等待确认）。

**retries**: 设置生产者发送失败时的重试次数。

**batch.size**: 设置每个批次的内存大小，单位为字节。生产者会尝试以批处理的方式发送消息，以提高吞吐量。

**linger.ms**: 设置生产者在发送批次之前等待更多消息加入批次的时间。增加这个值可能会减少请求的数量，但会增加消息的延迟。

**buffer.memory**: 设置生产者用于缓冲等待发送到服务器的记录的总内存量，单位为字节。

**compression.type**: 设置生产者使用的压缩类型，可以是`"none"`、`"gzip"`、`"snappy"`、`"lz4"`或`"zstd"`。

**max.in.flight.requests.per.connection**: 设置生产者在一个连接上可以发送的未确认请求的最大数量。

**enable.idempotence**: 启用幂等生产者以确保每条消息只会被发送一次，并且按顺序发送。设置为`true`时，可以防止重复消息。

**client.id**: 设置生产者的标识符字符串，服务器端用于日志和配额中，以便于跟踪消息来源。

**request.timeout.ms**: 设置生产者发送请求后等待服务器返回响应的时间，超过这个时间后会进行重试。

**delivery.timeout.ms**: 设置消息发送的总超时时间，包括重试时间。这个参数确保了消息在指定时间内发送，否则失败。



## 3. Kafka异步发送如何知道消息发送失败？

异步发送消息时，生产者通常会在代码中提供一个回调函数（callback），用于处理发送成功或失败的情况。这使得你可以在消息发送失败时及时做出响应。具体来说，你可以通过以下方式知道消息发送是否失败：

**回调函数 (Callback)**: 在生产者的 `send` 方法中，你可以传入一个 `Callback` 对象。这个对象包含两个方法：`onCompletion` 和 `onFailure`。`onCompletion` 方法在消息成功发送到Kafka时被调用，`onFailure` 方法在发送失败时被调用。回调函数提供了处理成功和失败逻辑的机会。

**异常处理**: 在回调函数中，可以捕获异常来处理发送失败的情况。通常，这些异常会包含有关错误的详细信息，如网络问题、Kafka集群不可用等。

**日志**: Kafka生产者通常会记录发送失败的详细日志，这些日志可以帮助你诊断问题。

**重试机制**: Kafka生产者提供了重试机制，允许你在发送失败时进行自动重试。通过设置 `retries` 参数，你可以指定生产者尝试发送消息的次数。但即使有重试机制，最终仍然需要通过回调函数或异常处理来知道消息是否最终成功发送。

**发送超时**: 通过设置 `request.timeout.ms` 和 `delivery.timeout.ms` 参数，你可以控制发送请求的超时时间。如果在这些超时时间内消息未能成功发送，生产者会认为发送失败，并触发回调函数中的 `onFailure` 方法。



## Kafka消息发送失败时会如何处理？

### 1. **同步发送和异步发送的处理**

- **同步发送**：如果你使用同步方式发送消息（即通过`producer.send(record).get()`），那么发送失败时会抛出一个异常，通常是`TimeoutException`或`KafkaException`。你可以捕获这个异常并进行相应的处理，如重试或记录错误。
- **异步发送**：在异步发送中，消息是通过`producer.send(record, callback)`方法发送的。你可以提供一个回调函数（Callback），这个函数会在消息发送成功或失败时被调用。如果发送失败，回调函数会接收到一个非空的异常对象，指示失败原因。

### 2. **重试机制**

Kafka生产者内置了重试机制，当消息发送失败时，生产者会自动进行重试。相关参数包括：

- **retries**：设置生产者在发送消息失败后自动重试的次数。如果重试次数超过了这个值，仍然会报告错误。
- **retry.backoff.ms**：设置重试之间的等待时间。

### 3. **错误处理**

- **日志记录**：生产者可以配置`error`级别的日志来记录发送失败的消息，以便日后分析。
- **死信队列（Dead Letter Queue, DLQ）**：一些企业级Kafka实现或自定义的应用逻辑中，当消息发送失败时，可以将这些消息转发到一个死信队列，供后续处理。
- **幂等性**：如果启用了幂等性（`enable.idempotence=true`），生产者将确保每条消息只会被写入一次，即使发生重试。

### 4. **确认（Acknowledgment）机制**

Kafka允许配置`acks`参数，控制生产者发送消息后是否等待服务器的确认以及多少个服务器的确认。这个参数直接影响消息发送失败后的处理方式：

- **acks=0**：生产者不等待任何确认。此时如果消息丢失，生产者不会收到任何通知。
- **acks=1**：生产者等待主节点的确认。如果主节点发送确认后崩溃，消息可能丢失。
- **acks=all**（或`acks=-1`）：生产者等待所有副本的确认。这是最安全的设置，但可能导致延迟较高。



## 如何保证缓存数据库的一致性？

### 1. **缓存更新策略**

- **Cache Aside（Lazy Loading 或 Lazy Caching）**: 这种模式是最常见的缓存使用模式，流程如下：
  1. 应用程序从缓存中读取数据。
  2. 如果缓存中有数据（缓存命中），则直接返回数据。
  3. 如果缓存中没有数据（缓存未命中），则从数据库中读取数据，并将数据写入缓存中，以备下次使用。
  4. 当写操作（更新或删除）发生时，首先更新数据库，然后使缓存中的数据失效（删除对应的缓存）。
- **Write Through**: 在这种模式下，所有的数据写操作（如创建、更新）都首先写入缓存，然后缓存负责将数据同步到后端数据库。
- **Write Behind（Write Back）**: 在这种模式下，数据首先写入缓存，并且缓存会异步地将数据更新到数据库。
- **Read Through**: 这种模式类似于 Cache Aside，不同之处在于应用程序不直接从数据库读取数据，而是由缓存负责从数据库中读取数据并将其返回给应用程序。

### 2. **分布式事务**

- **两阶段提交（Two-Phase Commit, 2PC）**: 通过使用分布式事务管理器，可以确保数据库和缓存的一致性。2PC 分为准备阶段和提交阶段。首先，所有涉及的资源（缓存和数据库）都准备好进行提交操作，然后再执行提交操作。这种方法能保证强一致性，但代价是性能开销较大，系统复杂度高。
- **分布式锁**: 在更新数据库和缓存时，可以使用分布式锁来防止并发写入问题。比如在 Redis 中使用 `SETNX` 命令来获取锁，确保在锁的持有期间不会有其他进程修改数据。

### 3. **最终一致性策略**

- **异步更新**: 接受短暂的缓存与数据库不一致性，通过异步进程定期同步缓存和数据库。可以在缓存数据到期时，从数据库中重新加载数据，或者通过消息队列系统（如 Kafka）来异步更新缓存。
- **Cache Expiry（缓存过期机制）**: 设置缓存的过期时间（TTL），确保缓存中的数据最终会被刷新。这样，即使缓存和数据库暂时不一致，随着时间的推移，缓存会自动从数据库中获取最新数据。

### 4. **避免缓存穿透、击穿和雪崩**

- **缓存穿透**：防止缓存未命中的请求直接击穿到数据库。可以通过在缓存中存储空结果（如 NULL）来避免频繁访问数据库。
- **缓存击穿**：防止热点数据在失效后，短时间内大量请求同时访问数据库。可以使用加锁机制或提前更新缓存的策略。
- **缓存雪崩**：当大量缓存同时失效时，防止大量请求同时访问数据库。可以通过设置不同的缓存过期时间或使用二级缓存（如本地缓存）来缓解这个问题。

### 5. **使用一致性哈希**

如果缓存数据分布在多个节点上，可以使用一致性哈希算法来确保同一个数据请求始终指向同一个节点。这有助于避免数据不一致性问题，尤其是在节点扩展或收缩时。



## 场景题：QQ有一个活动，1亿QQ用户抢一个礼包，要在1秒内给用户返回成功或者失败，你要如何设计方案？

### 1. **请求分流和负载均衡**

- 使用全局的负载均衡器（如Nginx或LVS）将请求分发到不同的服务实例中。根据地理位置或其他因素，将流量分配到最近的数据中心，以减少网络延迟。
- 通过DNS或其他调度方式，提前将用户流量按区域、时间分布等策略进行分流，避免单点集中流量过大。

### 2. **分布式缓存预热**

- 在活动开始前，通过分布式缓存（如Redis、Memcached）预先加载抢礼包的库存状态和用户ID列表。
- 每个请求到达时，先在缓存中查询礼包的状态，若库存充足且用户未抢到，则尝试给用户分配礼包。

### 3. **令牌桶限流**

- 采用令牌桶算法在应用层进行限流，限制每个服务器在一定时间窗口内处理的请求数量，防止瞬时流量过大导致服务器崩溃。
- 在每个请求到达时，首先从令牌桶中取出令牌，如果有令牌则允许用户继续请求，否则直接返回失败结果。

### 4. **乐观锁和分布式事务**

- 在缓存中对每次抢礼包操作进行原子性操作，利用Redis的`INCR`或`DECR`命令保证同一时刻只有一个请求可以成功抢到礼包。
- 结合乐观锁机制，避免多个请求同时抢同一个礼包。在尝试扣减库存时，使用Redis的`WATCH`机制确保库存状态的一致性。

### 5. **异步队列与消息系统**

- 使用消息队列（如Kafka、RabbitMQ）对抢礼包请求进行异步处理，将请求先写入队列中，后台异步消费处理。
- 对于处理成功的用户，通过异步的方式告知用户成功，失败的用户也能在短时间内收到失败反馈。

### 6. **多级缓存和回源机制**

- 利用多级缓存（L1、L2缓存）加速查询，如遇到缓存穿透则访问数据库，但要防止数据库直接受到高并发压力。
- 在极端情况下，如缓存层无法提供服务，设计回源机制从数据库直接获取数据，但要做好防护策略。

### 7. **日志与监控**

- 全程记录抢礼包的请求日志，并对各个环节进行监控。特别是对请求量、成功率、失败率等关键指标进行实时监控，及时发现问题。
- 通过日志分析找出潜在的瓶颈，并对系统进行动态调整。

### 8. **结果反馈**

- 成功抢到礼包的用户，直接反馈成功信息，并扣减库存。失败的用户直接反馈失败信息，不做库存操作。
- 所有反馈操作都应该在毫秒级内完成，尽可能减少用户等待时间。

### 9. **预案与扩展**

- 设计应急预案，如在短时间内流量激增时，自动扩展服务器实例、临时关闭部分服务或进行流量控制。
- 活动前充分进行压测，确保系统能够承受峰值流量。



## 场景题：每个QQ群有1000个用户同时查询群资料，如何设计方案，减少下游的查询量？

### 1. **缓存机制**

- **本地缓存**：客户端可以缓存一段时间的群资料，用户再次查询时先从本地缓存获取。如果缓存过期或未命中，再发起查询请求。
- **服务器端缓存**：在服务器端缓存群资料，设置一定的缓存过期时间。客户端请求时先从缓存中获取数据，减少数据库的查询量。

### 2. **批量查询**

- **批量请求**：当多个用户同时查询群资料时，合并请求为一个批量查询。服务端合并这些请求，统一进行查询，返回结果后再分发给各个客户端。

### 3. **限流和请求队列**

- **限流**：在短时间内对相同群资料的查询请求进行限流，例如每秒钟只允许一定数量的请求通过，其余的请求被延迟或合并处理。
- **请求队列**：将所有查询请求放入队列中，并设置合理的处理速度，避免瞬间大量请求涌入下游服务。

### 4. **使用消息队列**

- **消息队列**：通过消息队列机制来缓冲和处理查询请求，队列中的消息可以根据优先级或批量方式处理，平滑地处理高并发查询。

### 5. **增量更新**

- **差异化更新**：对群资料的变化进行监听，并在发生变化时推送到客户端。这样客户端只需要监听更新事件，而无需频繁地查询完整资料。

### 6. **前端合并展示**

- **分段加载**：对于群资料，前端可以分段展示，仅在用户滚动或请求更多内容时才发起后续查询。避免一次性获取大量数据。

### 7. **预计算**

- **定时更新缓存**：定时将群资料进行预计算，并更新到缓存中。当用户查询时直接返回预计算的结果，减少实时查询带来的负担。

### 8. **利用CDN加速**

- **CDN缓存**：将常用或静态的群资料数据缓存到CDN（内容分发网络），用户查询时直接从CDN获取，减少对数据库的请求。

### 9. **后台任务异步处理**

- **异步更新**：将查询请求转化为异步任务，让后台在压力较小的时段进行查询和更新，用户可以接收稍后返回的查询结果。



## TCP为什么是三次握手而不是四次握手？

**三次握手已经足够确认双方状态：**

- 第一次握手：客户端请求连接，向服务器表明自己想要通信。
- 第二次握手：服务器同意连接，并确认已经收到了客户端的请求。
- 第三次握手：客户端确认收到了服务器的同意，并告知服务器连接建立成功。

在第三次握手完成后，双方都明确了彼此的状态，并且确认了连接的建立。此时双方都已经达成共识，可以开始数据传输了。

**四次握手会带来额外的开销和复杂度：**

- 引入第四次握手会增加协议的复杂度，但并不会带来额外的好处。三次握手已经足以确保双方都能确认连接的建立，并确保双方的通信状态是一致的。
- 过多的握手也会增加延迟，并降低协议的效率，尤其是在高延迟网络中。



## 有没有了解过Http/3.0

HTTP/2 通过头部压缩、二进制编码、多路复用、服务器推送等新特性大幅度提升了 HTTP/1.1 的性能，而美中不足的是 HTTP/2 协议是基于 TCP 实现的，于是存在的缺陷有三个。

- **队头阻塞**，HTTP/2 多个请求跑在一个 TCP 连接中，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经接收了，应用层也无法从内核中读取到这部分数据，从 HTTP 视角看，就是多个请求被阻塞了；
- **TCP 和 TLS 握手时延**，TCP三次握手和 TLS 四次握手，共有 3个RTT 的时延；
- **连接迁移需要重新连接**，移动设备从 4G 网络环境切换到 WIFI 时，由于 TCP 是基于四元组来确认一条 TCP 连接的，那么网络环境变化后，就会导致 IP 地址或端口变化，于是 TCP 只能断开连接，然后再重新建立连接，切换网络环境的成本高；

HTTP/3 就将传输层从 TCP 替换成了 UDP，并在 UDP 协议上开发了 QUIC 协议，来保证数据的可靠传输。

QUIC 协议的特点：

- **无队头阻塞**，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，也不会有底层协议限制，某个流发生丢包了，只会影响该流，其他流不受影响；
- **建立连接速度快**，因为 QUIC 内部包含 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与 TLS 密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。
- **连接迁移**，QUIC 协议没有用四元组的方式来“绑定”连接，而是通过「连接 ID」来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本；



![img](https://uploadfiles.nowcoder.com/images/20240801/1030032975_1722505513576/5DF83F4FD67CE25E96F56D6A635A372E)