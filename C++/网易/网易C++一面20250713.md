# 网易C++一面20250713

### **网易一面**

#### **自我介绍和项目介绍**

简单自我介绍下吧

balabala

你对哪方面是最熟的,是不是Linux C++ 或者说是最感兴趣?

表达自己倾向基础方向开发

问下项目经历吧，能不能详细介绍下这个项目里做了哪些事情，解决了什么问题啊？

详细的介绍了项目和之前准备好的一个问题(socket方向的，自己通过 netstat 等监控工具排查问题经过，讲得很详细，感觉面试官比较满意)

你中间有没有去提升或者改善性能啊，比如说改参数啊或者调整什么机制，有没有这方面的努力？

也是简单介绍了下自己怎么优化的，达到了什么效果(QPS)

蛮多和项目相关的问题就不细说了，反正就是大家准备项目的时候提前准备一些比如遇到的困难、如何解决的、性能如何、如何优化这样子的问题。

#### **基础**

你对 Linux 内核 IO 机制有没有了解，就比如说 select 和 epoll 有什么差别？

哈哈哈问到这个问题我就笑了，然后就开始先说差别，比如select 有文件描述符限制，频繁的内核态和用户态拷贝、O(n)遍历这些，然后讲了 select 和epoll 都是基于文件系统中 file_operations 的 poll 调用，然后开始详细讲 epoll，大概讲到了内核用红黑树维护监听描述符，就绪队列，回调函数机制避免O(n)的遍历这些，答完面试官就说说得比较全面深入。

## 刚才你说你用 netstat 命令去检查连接状态，你能不能说下这个命令是做什么，看到的链接状态会有哪些？





就讲了ESTABLISHED、SYN_RCVED、CLOSE_WAIT、TIME_WAIT(故意最后答这个引过来)

## 如果是你在部署某一个程序服务的时候，看到大量的TIME_WAIT连接是怎么回事？

- **场景一：作为HTTP服务器，处理大量短连接。**
  - 在HTTP/1.0或HTTP/1.1未使用Keep-Alive的情况下，典型的交互是：客户端请求 -> 服务器响应 -> **服务器主动关闭连接**。在高并发下，服务器每秒处理成千上万个请求，就会产生同样数量级的 TIME_WAIT 状态。这是最常见的原因。
- **场景二：作为微服务架构中的调用方（客户端）。**
  - 我的服务需要频繁地调用其他微服务（比如查询数据库、访问缓存Redis、调用下游API）。每次调用都建立一个新的TCP连接，用完后就**主动关闭**。这种模式下，我的服务作为客户端，会产生大量的 TIME_WAIT。
- **场景三：爬虫或压力测试程序。**
  - 这类程序会在短时间内发起海量的网络请求，并且每次请求都使用新的连接，用完即关。这也会在发起请求的机器上留下大量的 TIME_WAIT。



分析了 TIME_WAIT 是主动关闭一方，所以服务器应该是有大量短连接请求

那么大量的 TIME_WAIT 会导致什么问题呢？

大概从端口占用 2 MSL 不能使用，可能导致后续没有端口接受新连接之类方向分析

## 那我们怎么去避免这个问题，避免大量 TIME_WAIT

讲了设置 socket 选项 SO_LINGER 或者设置 SO_REUSEADDR 让端口和地址重用

#### **第一层：应用层优化 (治本之策，优先推荐)**

这是最根本、最安全的解决方案，因为它从源头上减少了连接的创建和关闭。

1. **启用长连接 (Keep-Alive)**:
   - 对于HTTP服务，开启并合理配置HTTP Keep-Alive。这允许客户端在同一个TCP连接上发送多个请求，极大地减少了连接数和 TIME_WAIT 的数量。
   - 对于微服务调用，客户端SDK通常也支持配置长连接或连接池。
2. **使用连接池 (Connection Pooling)**:
   - 对于数据库、Redis等后端服务的调用，必须使用连接池。从池中获取连接，用完后归还到池中，而不是关闭它。这几乎能完全避免客户端侧的 TIME_WAIT 问题。

#### **第二层：操作系统内核参数调优 (辅助手段，谨慎使用)**

当应用层优化无法实施或效果有限时，可以考虑调整内核参数。我会非常小心，并清楚每个参数的含义和副作用。

1. **开启 tcp_tw_reuse (推荐)**:
   - **命令**: sysctl -w net.ipv4.tcp_tw_reuse=1
   - **作用**: 这个参数允许内核在**创建新的出站连接**时，复用处于 TIME_WAIT 状态的socket。它不是直接销毁 TIME_WAIT，而是在需要时“抄近道”。
   - **安全性**: 它相对安全，因为内核会检查时间戳，确保新连接不会收到旧连接的延迟报文。这是解决客户端 TIME_WAIT 堆积导致端口耗尽问题的首选内核方案。
2. **缩短 tcp_fin_timeout (不推荐)**:
   - **命令**: sysctl -w net.ipv4.tcp_fin_timeout=30
   - **作用**: 这个参数修改的是MSL的值，从而缩短 TIME_WAIT 的等待时间。默认是60秒。
   - **风险**: 随意缩短这个时间违反了TCP协议的建议，可能会增加旧数据包干扰新连接的风险，尤其是在复杂的广域网环境中。我只会在充分评估风险后，作为最后的手段微调。
3. **调整 ip_local_port_range**:
   - **命令**: sysctl -w net.ipv4.ip_local_port_range="1024 65535"
   - **作用**: 扩大可用的源端口范围，提供更多的“弹药”，但这只是提高了TIME_WAIT的上限，治标不治本。
4. **关于 tcp_tw_recycle (强烈不推荐，已废弃)**:
   - **作用**: 这个参数能非常快速地回收 TIME_WAIT 连接。
   - **致命缺陷**: 它在判断报文时依赖于对端的时间戳，如果网络中有NAT设备（这在现代网络中极其普遍），会导致来自同一个NAT设备后方不同客户端的连接被误判为同一个，从而丢弃正常的SYN包，造成连接无法建立。
   - **现状**: 由于风险巨大，**Linux在内核4.12版本之后已经彻底移除了这个参数**。提及这一点可以展示我对技术演进的了解。我会明确指出这是一个过时且危险的选项





平时用什么语言，做什么开发？

C++ 一般用来和网络 Linux 相关的开发， Java 的话是偏 Web 后端， Python一般是写脚本或者爬虫也有用后端框架

Python的话用到过装饰器吗？

嗯，然后讲了装饰器来干嘛，比如无侵入的增加函数功能(比如计时)，有点类似 Java 注解，支持 AOP 编程。乱扯了一堆…

那 Java 你有哪些了解得常用设计模式？

讲了装饰器模式和在 jdk IO 流中的运用，单例模式

## 那单例我们一般用来做什么？

只需要一个对象的场景，比如数据库连接池、文件系统这种。。。

#### 配置管理类 (Configuration Manager)

#### 日志记录器 (Logger)

#### 数据库连接池 (Database Connection Pool)

#### 线程池 (Thread Pool) 或 协程池 (Coroutine Pool)

#### 硬件设备访问接口





了解过 Java 里面的线程安全问题吗？

感觉不妙引到 Java 上来了，赶紧给面试官说自己 Java 不是很熟悉，讲下 C++ 中的吧，然后开始 C++ 的问题

讲下 C++ 里虚函数

虚函数表 虚函数表指针 函数指针 动态绑定 基类指针指向派生类对象这些，还有接口设计方面

在 C++ 里面结构体和类的区别

默认访问权限 + 一点其它自己的使用感觉

用过智能指针吗，能不能介绍下它解决的问题和你使用的经验？

首先讲了裸指针生命周期管理的困难，内存泄漏、野指针这些

然后讲了智能指针是如何利用 RAII 来解决的，然后顺便提了那几个智能指针区别

讲了自己项目中如何利用 shared_ptr 的，还有如何用 weak_ptr 解决环形引用的



## 刚才你提到内存泄漏，那你是如何在 debug 发现或者是定位内存泄漏的呢？

讲了下 Valgrind 套件下的 memcheck





那后面用了智能指针之后你再去跑内存泄漏有减少吗？

嗯，工具检测没有内存泄漏发生了

可以讲下树的深度遍历和广度遍历

前 中 后 用栈或者递归

层次 用队列

讲一下 hash 表

详细讲了下 STL unordered_map 底层

那哈希表冲突怎么解决？

线性探测和平方探测，说了这两个有主聚集和次聚集缺点

大多数语言 map 用的是开链法

如何判断链表是否有环？

说了用 set 和快慢指针两种

OK，我问几个操作系统方面的问题哈

#### **OS**

## 你知道 copy on write 吗

详细讲了 fork 的COW, 锁定父子进程页表只读，任何一进程写时就分配页框复制之类，顺便还提了下 C++ 中 COW 在string 上的应用

+ #### Linux 的 fork() 系统调用 

+ **C++ 的** **std::string** **(C++11之前)**

+ **Go 的切片 (Slice)**

+ COW是现代文件系统（如Btrfs, ZFS）和存储虚拟化（如LVM）实现快照（Snapshot）功能的核心技术。

+ **内核同页合并 (Kernel Same-page Merging, KSM)**



实现进程间通信的方式

## 匿名管道 有名管道 共享内存 信号量 消息队列 socket， 然后强调自己偏向使用 socket 通信，因为方便将单机多进程扩展到多机多进程

| IPC机制          | 速度          | 复杂度          | 适用范围           | 关键场景                     |
| ---------------- | ------------- | --------------- | ------------------ | ---------------------------- |
| **匿名管道**     | 较快          | 极低            | 父子/兄弟进程      | Shell命令，简单父子通信      |
| **命名管道**     | 较快          | 低              | 同一主机，任意进程 | 单机C/S，日志收集            |
| **消息队列**     | 中等          | 中等            | 同一主机，任意进程 | 任务分发，异步处理           |
| **信号量**       | N/A (同步)    | 中等            | 同一主机，任意进程 | 进程间锁，资源控制           |
| **共享内存**     | **最快**      | 高 (需手动同步) | 同一主机，任意进程 | **大数据量、高性能**数据交换 |
| **Unix域套接字** | 很快          | 中等            | 同一主机，任意进程 | **高性能**本地C/S通信        |
| **网络套接字**   | 慢 (网络开销) | 中等            | **跨网络**         | **所有网络应用、分布式系统** |





你单机开发和实验用的什么 Linux 开发版啊？

讲了 Ubuntu 和 deepin

了解一些运维命令吗，比如你在测试的时候怎么看负载啊

答了 top

## 后面详细问了 top, 比如问我知道 Load Avg 代表什么含义，进程的 CPU 利用率会超过 100% 吗，top 还能看什么性能指标？

+ Load Average 表示的是在特定时间间隔内，系统中**处于可运行状态（Running）和不可中断睡眠状态（Uninterruptible Sleep）的平均进程数**。
+ 果一个系统CPU利用率不高，但 Load Average 很高，这通常意味着存在 **I/O瓶颈**。大量的进程在等待缓慢的磁盘或网络响应，它们虽然不消耗CPU，但同样占用了系统资源，导致系统整体响应缓慢。只看CPU利用率会忽略这种严重的问题。



+ **100% CPU 利用率指的是一个单独的CPU核心被完全占满**



+ 内存， 进程



你有什么问题问我吗