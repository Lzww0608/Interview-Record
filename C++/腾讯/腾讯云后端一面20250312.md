# 腾讯云后端一面20250312

腾讯云-后台开发-一面

鼠鼠我来攒人品了~~~
3.3投递 3.5约面 3.6一面
自我介绍
（拷打实习）
说说线程池

## 线程池死锁的原因

1. **任务提交线程等待任务执行完成 (最常见的情况)：**  这是最经典的线程池死锁场景。  **当一个任务 (比如任务 A) 在线程池的线程中执行时，它又向 同一个 线程池提交了 另一个 任务 (比如任务 B)，并且任务 A 需要等待任务 B 执行完成后才能继续执行或完成。**
2. **任务之间存在循环依赖关系：**  多个任务之间可能存在复杂的依赖关系，例如任务 1 依赖任务 2 的结果，任务 2 又依赖任务 3 的结果，...，任务 N 又依赖任务 1 的结果，形成一个循环依赖链。
3. **任务执行过程中请求外部资源导致阻塞：**  任务在执行过程中可能需要请求外部资源，例如数据库连接、网络连接、文件锁等。



## 如果线上线程池出现死锁怎么监控，怎么排查，怎么解决





线程池分配线程时是怎么调度的（操作系统层面）





线上遇到流量激增，大量请求同时出现打垮线程池该怎么处理





线程池中如果出现嵌套任务依赖的情况，且父线程会阻塞等待子线程的情况下，该如何设计并发逻辑避免可能出现的问题

有经历过慢sql吗
线上出现慢sql怎么监控，怎么排查，怎么解决
为什么有的时候设置了索引但是查询的时候不会走索引
索引还有什么情况下会失效



## 聚簇索引是什么，从硬件角度和逻辑角度分析聚簇索引这样设计的必要性

聚簇索引的核心特点是**数据行的物理存储顺序与聚簇索引的索引顺序一致**。  这意味着，当我们按照聚簇索引的顺序访问数据时，可以实现**顺序 I/O**。  试想一下：

- **数据局部性 (Data Locality):** 由于数据是按照索引键值物理排序的，**相同或相近索引键值的数据行在磁盘上也是相邻存储的**。 这样，当我们查询一个范围内的数据，或者按照索引顺序扫描数据时，可以**一次性读取连续的数据块 (Page)**，减少磁盘寻道次数，提高 I/O 效率。 这就像在图书馆找书，如果书是按照书名首字母排序的，那么找同一类别的书就会非常方便，因为它们都放在一起。
- **减少磁盘寻道 (Reduced Disk Seeks):** 顺序 I/O 相比随机 I/O，磁盘磁头移动距离更小，寻道时间更短。 聚簇索引通过物理排序数据，将随机 I/O 尽可能地转化为顺序 I/O，**显著降低了磁盘寻道开销**。 对于需要扫描大量数据的查询，例如范围查询、全表扫描 (在聚簇索引列上)，顺序 I/O 的优势会更加明显。

**总结来说，从硬件角度看，聚簇索引的设计，本质上是一种 “以空间换时间” 的策略。  它通过维护数据的物理有序性，牺牲了一定的插入和更新性能 (因为需要维护物理顺序)，换取了查询性能的巨大提升，尤其是在磁盘 I/O 成为瓶颈的场景下，这种优化是非常必要的。**

**其次，从逻辑角度来看，聚簇索引的设计也符合数据查询和管理的逻辑需求，提供了更高效的数据访问路径。**

- **提高查询效率 (Query Efficiency):** 对于基于聚簇索引列的查询，特别是**主键查询和范围查询**，聚簇索引可以提供非常高的查询效率。 因为索引叶子节点直接存储的就是数据行本身，无需像非聚簇索引那样还需要通过指针 (或书签) 回表查询数据行。 这相当于**索引和数据存储合二为一**，减少了一次数据查找的过程。
- **支持高效的范围查询 (Efficient Range Scans):** 由于数据物理有序，范围查询可以直接利用索引的顺序性，**高效地扫描连续的数据块**，而无需像非聚簇索引那样可能需要多次随机 I/O 来获取范围内的所有数据行。 例如，查询某个时间段内的订单数据，如果订单表按照订单时间建立聚簇索引，范围查询效率会非常高。
- **支持排序操作 (Sorting Operations):** 当查询结果需要按照聚簇索引列排序时，由于数据本身已经物理有序，数据库可以直接返回有序结果，**避免了额外的排序操作**，进一步提升了性能。 例如，`ORDER BY` 子句如果使用聚簇索引列，可以利用索引的有序性进行优化。
- **简化数据访问路径 (Simplified Data Access Path):** 聚簇索引将索引和数据行存储在一起，**简化了数据访问路径**。 对于需要访问完整数据行的查询，聚簇索引只需要一次索引查找即可获取所有数据，而非聚簇索引则需要先找到索引，再通过索引指向的数据地址去磁盘上读取数据，访问路径更长。



## 线上cpu突然飙升该怎么定位问题

**系统层面 (System Level):**

- **CPU 使用率 (CPU Utilization):** 使用 `top`, `htop`, `vmstat`, `pidstat` 等 Linux 命令，查看 **哪个进程 (PID) 占用了大量的 CPU 资源**。 `top -H` 可以查看进程内线程的 CPU 使用情况。 `pidstat -p <pid> 1` 可以查看指定进程的 CPU 使用率。
- **I/O 等待 (I/O Wait):** 使用 `iostat`, `vmstat` 等命令，查看 **I/O 等待是否过高**。 如果 I/O 等待高，说明 CPU 可能在等待 I/O 操作完成，问题可能出在磁盘 I/O 瓶颈，例如慢 SQL 查询、大量磁盘读写操作等。
- **上下文切换 (Context Switch):** 使用 `vmstat` 命令，查看 `cs` (context switch) 列，**上下文切换次数是否异常增高**。 如果上下文切换频繁，说明线程/进程切换开销大，可能是线程竞争激烈、锁冲突严重等原因导致。
- **系统资源限制 (Resource Limits):** 检查 **ulimit** 等系统资源限制，例如文件句柄数、线程数等，是否设置过小，导致程序运行受限。

**应用层面 (Application Level):**

- **GC (Garbage Collection) 频繁 (Java 场景常见):** 如果应用是 Java 应用，**频繁的 Full GC** 会消耗大量 CPU 资源。 可以使用 `jstat -gcutil <pid> 1000 10` 命令查看 GC 统计信息，或者使用 GC 日志分析工具 (例如 GCeasy, GCViewer) 分析 GC 日志，判断是否是 GC 导致 CPU 飙升。
- **线程池状态 (Thread Pool Status):** 检查应用线程池的状态，例如**活跃线程数、队列长度、拒绝任务数**等。 线程池配置不合理、任务积压、线程死锁等都可能导致 CPU 升高。 可以通过应用自身的监控指标或者 JMX (Java) 等方式查看线程池状态。
- **外部依赖 (External Dependencies) 慢响应:** 检查应用依赖的外部服务，例如数据库、缓存、第三方 API 等，**是否存在慢响应或超时**。 应用在等待外部服务响应时，线程可能处于阻塞状态，但如果阻塞线程过多，也可能累积导致 CPU 升高。 需要查看应用日志、调用链监控 (例如 SkyWalking, Zipkin) 等工具。
- **日志级别过高或日志量过大:** 如果应用配置了过高的日志级别 (例如 DEBUG, TRACE)，或者日志量突然增大，**大量的日志打印操作** (特别是同步日志) 会消耗 CPU 资源。 检查应用的日志配置和日志输出量。



## tcp和udp的区别





## tcp在三次握手后，如果服务端网络出现延迟，客户端如何保证传输的可靠性

1. **序列号和确认应答 (Sequence Number & ACK) 的持续作用：**  即使服务端网络延迟，客户端发送的每个数据包仍然会携带序列号。  服务端在最终成功接收数据包后，仍然会按照 TCP 协议规范发送 ACK。  **关键在于，TCP 的可靠性机制是端到端的，只要最终能收到 ACK，客户端就认为数据传输是成功的，中间的网络延迟只是影响了传输时间，但不会影响可靠性保证。**
2. **超时重传机制 (Timeout Retransmission) 的应对：**  服务端网络延迟可能导致 ACK 延迟到达客户端，甚至可能因为网络抖动导致 ACK 丢失。  **客户端的超时重传机制会发挥作用。**
   - **超时检测：** 客户端在发送数据包后，会启动一个 **重传定时器 (Retransmission Timer)**。 如果在这个定时器超时之前，没有收到服务端发来的 ACK，客户端就会认为数据包或 ACK 在网络传输过程中丢失或延迟过长。
   - **重传触发：** 定时器超时后，客户端会 **重新发送** 之前发送但未收到 ACK 的数据包。 **重要的是，客户端会重试，直到收到 ACK 或者达到最大重传次数 (通常情况下，TCP 会进行多次重传尝试)。** 即使服务端网络延迟很长，只要最终网络恢复，服务端能够收到重传的数据包并发送 ACK，客户端最终就能成功完成数据传输。
   - **动态超时时间调整 (RTO - Retransmission Timeout)：** TCP 协议栈会 **动态地调整重传定时器的超时时间 (RTO - Retransmission Timeout)**。 它会根据 **往返时间 (RTT - Round Trip Time)** 的估计值来调整 RTO。 如果网络延迟增加，RTT 也会增加，TCP 协议栈会相应地 **延长 RTO**，避免过早地触发不必要的重传。 这种 **自适应的超时机制** 使得 TCP 能够更好地适应不同网络延迟环境，减少不必要的重传，同时又能保证在网络延迟较高的情况下，依然能够通过重传机制最终保证可靠性。
3. **数据校验和 (Checksum) 的持续保障：**  数据校验和机制在整个数据传输过程中都有效。  即使服务端网络延迟导致数据包在网络中停留时间更长，校验和仍然可以保证客户端接收到的数据是完整的，没有被损坏的。
4. **流量控制 (Flow Control) 的潜在影响 (间接影响可靠性)：**  服务端网络延迟可能导致服务端处理速度变慢，接收缓冲区可能更快被填满。  这时，服务端会通过 **减少滑动窗口大小** 来通知客户端降低发送速率，进行流量控制。  **虽然流量控制的主要目的是防止接收端缓冲区溢出，但间接上也对可靠性有帮助，因为它避免了由于发送过快导致的网络拥塞和丢包，从而减少了重传的概率。**
5. **拥塞控制 (Congestion Control) 的潜在影响 (间接影响可靠性)：**  虽然题目描述的是服务端网络延迟，但网络延迟往往也可能与网络拥塞有关。  如果服务端网络延迟是由于网络拥塞造成的，客户端的拥塞控制机制也会发挥作用。  **客户端会根据网络状况 (例如丢包、延迟) 调整发送速率，降低网络负载，缓解拥塞，从而间接提高数据传输的成功率和可靠性。**  虽然拥塞控制的主要目的是避免网络崩溃，但它也为可靠传输提供了更稳定的网络环境。



算法：
    ● 接雨水
    ● 最大子数组和
面试官介绍了一下组里的业务