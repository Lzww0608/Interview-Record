# 滴滴后端实习一面20250303

自我介绍
实习拷打

## 如何保证数据库和缓存的一致性

- **最终一致性 (Eventual Consistency):**  允许在一段时间内，数据库和缓存之间的数据存在不一致的情况。但最终经过一段时间的同步，两者的数据会达到一致。这种策略更注重性能和可用性，适用于对数据实时性要求不高，可以容忍短暂数据不一致的场景，例如社交应用的非核心数据、电商商品的库存展示（允许短暂误差）等。
- **强一致性 (Strong Consistency):**  要求数据库和缓存中的数据在任何时刻都必须保持一致。一旦数据库数据发生变更，缓存数据也必须立即同步更新。这种策略更注重数据准确性，适用于对数据实时性要求极高，绝对不允许出现数据不一致的场景，例如金融交易、银行转账等。

**Cache-Aside Pattern (旁路缓存模式，也叫 Lazy Loading)**

这是最常用，也是最推荐的缓存模式。它的工作流程如下：

- **读操作 (Read):**
  1. 先查询缓存 (Cache)。
  2. 如果缓存命中 (Cache Hit)，直接返回缓存数据。
  3. 如果缓存未命中 (Cache Miss)，则查询数据库 (Database)。
  4. 从数据库读取数据后，**将数据写入缓存**，然后再返回给客户端。
- **写操作 (Write):**
  1. 先更新数据库 (Database)。
  2. **删除缓存 (Invalidate Cache)**。 **注意这里是删除缓存，而不是更新缓存。**

**优点：**

- **简单易懂，实现相对容易。**
- **读性能高：** 缓存命中率高的情况下，读操作直接从缓存返回，性能非常好。
- **数据库压力小：** 只有在缓存未命中时才访问数据库，有效降低数据库的负载。
- **最终一致性：** 通过删除缓存，在下一次读取时，会强制从数据库拉取最新数据并更新缓存，最终保证数据一致性。

**缺点：**

- **首次读取延迟高：** 首次读取数据时，缓存未命中，需要从数据库读取并写入缓存，会有一定的延迟。
- **写操作后可能短时间内读到旧数据：** 在删除缓存后，到下一次读取之前，如果并发请求过来，可能会发生缓存击穿，读取到旧数据。 （可以通过**互斥锁或分布式锁**来缓解缓存击穿问题，保证只有一个线程回源数据库并更新缓存）。
- **需要考虑缓存穿透问题：** 如果大量请求访问不存在的数据，会导致缓存一直未命中，每次都请求数据库，造成数据库压力。 （可以通过**布隆过滤器**或**缓存空值**等方式来解决缓存穿透问题）。

**为什么写操作是删除缓存而不是更新缓存？**

- **性能：** 更新缓存的成本通常比删除缓存要高。尤其是在高并发场景下，更新缓存可能会导致性能瓶颈。
- **数据不一致风险：** 更新缓存和数据库是两个独立的操作，如果更新缓存成功，但数据库更新失败，或者两者顺序不一致，都可能导致数据不一致。删除缓存则可以强制下一次读取时从数据库拉取最新数据，避免这类风险。
- **复杂性：** 更新缓存逻辑通常需要与数据库更新逻辑保持一致，如果数据模型复杂，更新缓存的逻辑也会变得复杂且容易出错。删除缓存则简化了写操作的逻辑。

**Cache-Aside Pattern 是最终一致性的策略，适用于大部分读多写少的业务场景，是实践中最常用的策略。**

延迟双删的核心思想是在 **删除缓存** 之后，**延迟一段时间** 再进行 **第二次删除缓存**。  因此，使用延迟双删的写操作步骤变为：

1. **删除缓存 (Cache - 第一次删除)**
2. **更新数据库 (Database)**
3. **延迟一段时间 (例如几百毫秒)**
4. **再次删除缓存 (Cache - 第二次删除)**



**分布式事务 (例如 2PC, TCC, Saga)  保证强一致性 (谨慎使用)**

在极少数对数据强一致性要求非常高的场景 (例如金融核心交易)，可以考虑使用分布式事务来保证数据库和缓存的强一致性。

- **两阶段提交 (2PC):**  经典分布式事务协议，保证事务的原子性。
  1. **Prepare 阶段：** 事务协调者通知所有参与者准备执行事务，参与者执行本地事务，但不提交，并返回准备结果 (成功或失败)。
  2. **Commit/Rollback 阶段：** 事务协调者根据所有参与者的准备结果，决定是提交事务还是回滚事务。 如果所有参与者都准备成功，则通知所有参与者提交事务；如果任何一个参与者准备失败，则通知所有参与者回滚事务。
- **TCC (Try-Confirm-Cancel):**  一种柔性事务模式，将事务分为 Try, Confirm, Cancel 三个阶段。
  1. **Try 阶段：** 尝试执行业务，完成所有业务检查 (一致性检查)，预留必要的业务资源 (例如冻结资金)。
  2. **Confirm 阶段：** 如果 Try 阶段所有参与者都成功，则执行 Confirm 操作，真正执行业务，提交事务，释放预留资源。
  3. **Cancel 阶段：** 如果 Try 阶段任何一个参与者失败，则执行 Cancel 操作，回滚业务，释放预留资源。
- **Saga 模式：**  将分布式事务拆分成多个本地事务，每个本地事务称为一个 Saga。 Saga 模式通过异步补偿的方式来保证最终一致性。

**优点：**

- **强一致性：** 分布式事务可以保证数据库和缓存的强一致性。 (2PC 和 TCC 更偏向强一致性， Saga 偏向最终一致性)

**缺点：**

- **性能极低：** 分布式事务的性能非常差，会严重降低系统的吞吐量和响应速度。 (尤其 2PC)
- **实现复杂：** 分布式事务的实现非常复杂，需要引入分布式事务框架，并对业务代码进行改造。
- **可用性降低：** 分布式事务增加了系统的复杂度，也增加了系统出错的概率，降低了系统的可用性。

**分布式事务 在绝大多数场景下都不是**保证数据库和缓存一致性的**最佳选择**。 只有在极少数对数据强一致性要求 **极端苛刻**，且能够接受性能和复杂性代价的场景下才考虑使用。  **更推荐使用最终一致性的策略，并结合业务逻辑来保证数据的最终正确性。**



采用消息队列保证的话，这个中间件有宕机风险怎么办



## 如何保证消息队列可靠性

- **集群部署 (Clustering):** 将 MQ 部署成集群模式，多个 MQ 节点组成一个集群。 当某个节点宕机时，集群中的其他节点可以接管其工作，保证服务的连续性。 例如 Kafka, RabbitMQ (Clustering), RocketMQ (集群模式) 都支持集群部署。
- **主从复制 (Replication):** 对于单机 MQ，可以采用主从复制的方式。 主节点负责处理消息的读写，从节点作为备份节点，实时同步主节点的数据。 当主节点宕机时，可以快速切换到从节点成为新的主节点。 例如 Redis (虽然 Redis 不是专门的消息队列，但其主从复制机制也可以借鉴)。
- **数据持久化 (Persistence):** 确保消息被持久化存储到磁盘，而不是仅仅保存在内存中。 即使 MQ 宕机重启，持久化的消息也可以从磁盘恢复，避免消息丢失。 大多数主流 MQ 都支持消息持久化。

## 如果生产后消息在传输过程中丢失，消息队列的持久化的意义在哪

1. **防止 MQ Broker 故障导致的数据丢失:**  这是持久化最核心的意义。  如果没有持久化，消息仅仅存储在内存中。一旦 MQ Broker 发生宕机、重启等故障，内存中的数据就会丢失。  持久化将消息写入到 **持久化存储介质 (例如磁盘)**，即使 Broker 宕机重启，消息数据仍然可以从磁盘中恢复，从而避免了消息在 MQ Broker 层面上的丢失。
   - **类比数据库的事务持久化:** 你可以把消息队列的持久化理解为数据库的事务持久化。 数据库为了保证事务的可靠性，需要将事务日志 (redo log) 持久化到磁盘，即使数据库服务器宕机，重启后也能通过 redo log 恢复事务的状态，保证数据不丢失。 消息队列的持久化也是类似的道理。
2. **为消息的可靠传输 (至少一次交付) 提供基础:**  即使消息在 *MQ Broker -> 消费者* 的传输过程中丢失 (第二种场景的第二种情况)，持久化仍然发挥作用。  因为消息已经安全地存储在 Broker 中。  MQ 可以利用持久化的消息进行重传，配合 **消息确认机制 (ACK)**，实现消息的 **至少一次交付 (At-Least-Once Delivery)** 语义。
   - **至少一次交付的流程 (简化版):**
     1. MQ Broker 将持久化的消息发送给消费者。
     2. 消费者成功处理消息后，向 MQ Broker 发送 ACK 确认消息已消费。
     3. 如果消费者没有发送 ACK，或者 Broker 没有收到 ACK (例如网络问题)，Broker 会认为消息没有被成功消费，会 **重传** 该消息 (由于消息是持久化的，Broker 可以安全地重传)。
     4. 消费者可能会收到重复的消息 (因此消费者需要保证 **幂等性**)，但至少能保证消息被成功处理一次。
   - **持久化是重传的基础:**  如果消息没有持久化，一旦 MQ Broker 发生故障，消息可能丢失，即使有重传机制，也无法重传已经丢失的消息。  持久化确保了重传的对象是存在的，即使在 Broker 发生故障后。
3. **支持离线消费和消息堆积:**  持久化使得消息可以被安全地存储在 MQ 中，即使消费者 **暂时离线 (例如消费者应用重启、维护等)**，消息也不会丢失。  当消费者重新上线后，可以继续消费之前积压在 MQ 中的消息。  这对于需要 **异步处理** 或 **削峰填谷** 的场景非常重要。
   - **消息堆积的场景:** 例如，在流量高峰期，生产者产生消息的速度远大于消费者消费速度，这时消息会暂时堆积在 MQ 中。 由于消息是持久化的，即使 Broker 压力增大或者发生重启，堆积的消息也不会丢失，消费者可以在流量低谷期逐步消费积压的消息



## 如何解决重复消费

要解决重复消费问题，最根本的方案是让 **消费者端的操作具备幂等性**。  **幂等性** 的含义是： **对于同一个请求 (或消息)，无论执行多少次，最终的结果都应该和执行一次的结果相同，不会对系统产生额外的副作用。**

**1.  利用唯一 ID (Message ID 或 Business ID)**

**2.  利用数据库的唯一约束 (Unique Index 或 Primary Key)**



## 消息队列支持事务吗

- **Apache Kafka:** Kafka 从 0.11 版本开始引入了 **事务 (Transactions)** 特性，支持生产者事务和消费者事务 (主要用于 Exactly-Once 语义消费)。 Kafka 的事务机制相对复杂，但功能强大，能够提供端到端的 Exactly-Once 语义。
- **Apache RocketMQ:** RocketMQ 从早期版本就提供了 **事务消息 (Transactional Message)** 特性。 RocketMQ 的事务消息实现相对简单易用，也能够保证消息发送的事务性。
- **RabbitMQ:** RabbitMQ 本身 **没有原生的事务消息** 支持。 但可以通过使用 **RabbitMQ 的事务 (Channel Transaction)** 和 **发布确认机制 (Publisher Confirms)** 来模拟实现类似事务的效果，但实现较为复杂，且性能会有所影响。 另外，一些 RabbitMQ 的插件或扩展 (例如 `rabbitmq-transactional-exchange`) 也提供了事务性 exchange 的支持。
- **ActiveMQ:** ActiveMQ 支持 **JMS 事务 (JMS Transactions)**，可以用于实现消息发送和消费的事务性
- **Zeromq:**不支持



## 对比 MySQL 和 Redis 的事务机制

| 特性          | MySQL (InnoDB)                            | Redis                                                 |
| ------------- | ----------------------------------------- | ----------------------------------------------------- |
| **事务类型**  | ACID (传统事务)                           | 乐观事务 (基于 WATCH)                                 |
| **ACID 支持** | 完全支持                                  | 部分支持 (原子性、隔离性较好，一致性、持久性相对较弱) |
| **原子性**    | 完全原子性 (支持回滚)                     | 命令队列原子执行 (无回滚)                             |
| **一致性**    | 强一致性 (数据完整性约束、触发器)         | 应用层一致性 (依赖开发者处理)                         |
| **隔离性**    | 多种隔离级别 (默认可重复读)，MVCC、锁机制 | 单线程模型，WATCH 命令 (乐观锁)                       |
| **持久性**    | 强持久性 (保证数据不丢失)                 | 可配置持久性 (性能与可靠性权衡)                       |
| **回滚机制**  | 完全回滚 (SERVER 端)                      | 有限回滚 (CLIENT 端逻辑处理)                          |
| **并发控制**  | 悲观锁 (锁机制)、乐观锁 (MVCC)            | 乐观锁 (WATCH)                                        |
| **性能**      | 相对较低 (ACID 开销)                      | 极高 (内存操作，单线程)                               |
| **适用场景**  | 高数据一致性、高可靠性、复杂事务场景      | 高性能、高并发、缓存、计数器等                        |



## Redis 事务支持回滚吗，为什么不支持

- **Redis:** **不提供传统意义上的回滚 (rollback) 机制**。 如果事务执行过程中发生错误，Redis 只会停止执行事务队列中剩余的命令，已经执行成功的命令不会回滚。 对于 `WATCH` 命令监控的 key 被修改的情况，Redis 会取消事务，但 **不会自动回滚已经执行的命令**，需要 **客户端自行处理事务失败的情况，并决定是否重试或进行补偿操作**。 因此，Redis 的回滚更多需要 **客户端的逻辑来实现**。



## Redis 有哪些搭建集群的方案

哨兵、集群、分片



了解 Memcached、etcd、zookeeper 等其他吗

## redis 的主从复制原理

将数据从master节点异步复制到多个slave节点，全量同步（rdb） 和 增量同步

- **RDB 持久化:** RDB 快照文件主要用于 **全量同步**。 Master 节点使用 `BGSAVE` 生成 RDB 文件，并将 RDB 文件发送给 Slave 节点进行数据同步。
- **AOF 持久化:** AOF 日志主要用于 **数据持久化和故障恢复**。 在主从复制过程中，**命令传播 (增量同步) 本身就是一种日志同步的方式**，但 AOF 日志本身并不直接用于主从复制的同步过程。 **不过，开启 AOF 持久化的 Master 节点在重启后，可以更快地恢复数据，减少全量同步的需要。** Slave 节点也可以配置 AOF 持久化，用于数据持久化和故障恢复。



## AOF 和 RDB



## AOF 和 RDB 分别在什么场景

RDB:

+ 数据备份和灾难恢复
+ 大规模数据，追求速度和性能
+ 数据完整性要求不高，可以容忍一定的数据丢失

AOF:

+ 追求安全性，减少数据丢失
+ 记录操作日志，故障排查



## CAP 了解吗

CAP 定理 (CAP Theorem)，也称为 Brewer's Theorem，是分布式计算领域的一个基本理论，它描述了在设计分布式系统时，我们 **不可能同时完全满足以下三个核心属性**：

- **一致性 (Consistency - C):**  所有节点在同一时间看到相同的数据快照。  换句话说，对分布式系统的任何数据写入操作，所有节点在读取时要么获得最近的写入值，要么获得写入失败的错误响应。  就好像只有一个数据副本一样。 这通常被称为 **强一致性 (Strong Consistency)** 或 **线性一致性 (Linearizability)**。
- **可用性 (Availability - A):**  每个请求都能获得成功的响应，无论系统中的某些节点是否发生故障。  可用性关注的是系统的响应能力。  即使系统部分出现问题，对于客户端来说，也应该始终能够获得服务，并且是非错误的响应（并不保证是最新的数据，但必须是有效的响应）。
- **分区容错性 (Partition Tolerance - P):**  即使网络发生分区 (网络故障导致系统被分隔成多个独立的子网络，节点之间无法互相通信)，系统仍然能够继续运行。  分区容错性是分布式系统的基本要求，因为在实际环境中，网络分区是不可避免的。

**CAP 定理的核心结论是：在存在网络分区的情况下，一致性 (Consistency) 和可用性 (Availability) 只能选择其二，不可兼得。 你必须在两者之间做出权衡和妥协。**



## 你觉得 Redis 是哪种类型

偏向AP



其他缓存有了解吗

## redis 的数据类型

简单字符串、列表、集合、有序集合、哈希   位图、流、地理位置索引、hyperloglogs概率数据结构



## redis4.0/5.0/6.0 的区别是什么

| 特性               | Redis 4.0                            | Redis 5.0                                                | Redis 6.0                                                    |
| ------------------ | ------------------------------------ | -------------------------------------------------------- | ------------------------------------------------------------ |
| **核心新数据类型** | 无                                   | **Streams** (流数据类型)                                 | 无 (但 RESP3 协议增强了数据类型表达能力)                     |
| **模块化系统**     | **Redis Modules** (模块化系统)       | 模块系统持续发展                                         | 模块系统持续发展                                             |
| **复制增强**       | **PSYNC2** (更高效的增量复制)        | 无重大更新                                               | 无重大更新                                                   |
| **集群增强**       | 无重大更新                           | **Cluster 性能和稳定性提升**                             | **Cluster Link Slots Cache** (优化 Cluster 性能)             |
| **脚本**           | Lua 脚本改进 (函数库、debugging)     | Lua 脚本改进 (`redis.call.ro` 只读命令)                  | 无重大更新                                                   |
| **安全性**         | 无重大更新                           | 无重大更新                                               | **ACL (Access Control List) 访问控制列表** (用户权限管理)    |
| **客户端缓存**     | 无                                   | 无                                                       | **Client-Side Caching (客户端缓存)** (配合 RESP3 协议)       |
| **协议**           | RESP2                                | RESP2                                                    | **RESP3 协议** (可选，向下兼容 RESP2)                        |
| **其他**           | **Active Defrag** (活动内存碎片整理) | **List 和 Sorted Set 命令改进** (ZPOPPMAX/MIN, LMOVE 等) | **Multi-threading I/O** (多线程 I/O，但计算仍然是单线程)  , **Diskless Replication** (无磁盘复制) |



## 大key和热key是什么，有什么危害，怎么解决

大key：

危害：

+ 内存占用过高
+ 阻塞Redis服务
+ 影响性能

解决：

+ 拆分、数据压缩
+ 已经存在的话可以删除或者迁移拆分

热key：

危害：

+ 频繁访问，该节点成为CPU、网络带宽瓶颈
+ 缓存击穿风险

解决：

+ 业务逻辑优化
+ 二级缓存
+ 已经存在的话，将热key分离或者复制，限流降级



## 写一个 Linux 命令，统计一个一个日志文件存放了请求信息（包括IP、ID等）统计UV和PV





Linux 常用命令了解吗
awk 知道吗



## TIME_WAIT 堆积是什么原因如何解决





## DNS 在哪一层

应用层

## DNS 基于什么协议实现

一般是UDP

## DNS 为什么不用TCP

+ 速度效率高
+ 请求-应答模式
+ 客户端负责重试，减少服务器压力



## MySQL 执行一条更新语句过程是什么，底层不同日志的记录顺序是什么样的

1. 客户端发起`UPDATE`请求
2. 连接器处理
3. 查询缓存（8.0前）
4. 解析器、预处理器、优化器、执行器
5. InnoDB存储引擎
   1. 查找行、读取到buffer
   2. 行锁、修改
   3. undo log， redo log， binlog
   4. 提交

日志顺序：

1. undo log
2. redo log
3. binlog （主从复制）



请教一下大家数据库和缓存的一致性这块怎么答比较好，今天多答了引入消息队列被质疑每增加一个中间件都会带来风险，重点是不是放在回答【先更新数据库 + 再删除缓存】和【延时双删】上，就不提消息队列了？