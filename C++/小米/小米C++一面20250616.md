# 小米C++一面20250616

面试官先介绍了下部门情况，问我意愿。那么继续面试。



自我介绍

## socket使用过程

+ 服务器： socket(), bind(), listen(), accept(), read()/write(), send()/recv(), close()
+ 客户端：socket(), connect(), write()/read(),  send()/recv(), close()



访问`www.baidu.com`的过程

内网地址和外网地址是怎么转换的。

## 网关是做什么用的，（我不太清楚，扯到`arp`协议上了）

它通过提供统一的流量入口，解耦了客户端与后端微服务，并将认证、限流、监控等通用功能进行集中处理，极大地提升了分布式系统的安全性、健壮性和可维护性。



## 服务端处理客户端的请求是并行还是串行

**一、 宏观层面：服务器同时处理多个客户端请求，一定是并行的**

现代高性能服务器设计的首要目标就是尽可能地提高吞吐量，同时服务海量的客户端连接。为了实现这一点，服务器在处理不同客户端的请求时，在宏观上必然是**并行 (Parallel)** 的。这主要通过以下两种方式实现：

1. **多进程/多线程模型：** 最经典的模型，如 Apache 的 `prefork` 模式，会为每个请求分配一个进程或线程。这种方式实现简单，但资源开销大，可扩展性差，现在已较少用于高性能场景。

2. I/O多路复用 + 线程池模型（主流）：

    这是现代C++后端服务（如Nginx、Envoy以及我们自己基于asio/brpc等库构建的服务）普遍采用的架构。 

   - **I/O层面 - 并发处理连接：** 服务器通常会有一个或少数几个专门的I/O线程（或称为Reactor线程）。这些线程利用 `epoll` (Linux) 或 `kqueue` (BSD/macOS) 这样的系统调用，可以**同时监听**成千上万个网络连接的事件（如数据到达、可以发送数据等）。当任何一个连接有事件发生时，I/O线程被唤醒并处理。这个过程是**异步非阻塞**的，使得单个线程就能高效地管理海量连接，实现了**网络I/O的并发处理**。
   - **业务逻辑层面 - 并行处理请求：** 当I/O线程接收到一个完整的请求后，它不会自己去执行耗时的业务逻辑，因为这会阻塞后续所有其他连接的I/O事件。它会将这个请求封装成一个任务，然后**投递到一个后端的“工作线程池” (Worker Thread Pool)** 中。线程池中有多个工作线程，它们会从任务队列中领取任务并**并行地执行**业务逻辑。

所以，从整体上看，服务器通过 **“异步I/O线程 + 同步执行的线程池”** 的模式，完美地实现了对多个客户端请求的并行处理。

**二、 微观层面：单个请求的内部处理，可能是串行也可能是并行**

当我们聚焦于一个请求被工作线程处理的过程时，情况会更加复杂：

1. **大多数情况是串行的：** 对于一个简单的业务逻辑，比如“根据用户ID查询数据库并返回用户信息”，这个过程在工作线程内部通常是**串行**执行的。代码从上到下依次执行：参数校验 -> 查询数据库 -> 构造响应 -> 返回。
2. **复杂情况可以是并行的：**考虑一个更复杂的场景，比如电商首页的聚合请求。这个请求可能需要同时获取用户信息、推荐商品列表和广告位信息，这三者分别依赖于不同的下游微服务。 
   - 如果**串行**调用这三个服务，总耗时 = T1 + T2 + T3。
   - 为了优化延迟，我们完全可以在工作线程内部发起三个**并行**的RPC调用（例如，使用C++的 `std::async` 或 `folly::Future`、`brpc` 的 `ParallelChannel` 等机制）。这样，总耗时就约等于 `max(T1, T2, T3)`，极大地降低了请求的响应时间。这种对请求内部逻辑的并行化，是服务性能优化的一个重要手段。



## http的keepalive和TCP的keepalive

| 特性         | HTTP Keep-Alive                                | TCP Keepalive                                  |
| ------------ | ---------------------------------------------- | ---------------------------------------------- |
| **协议层级** | **应用层 (L7)**                                | **传输层 (L4)**                                |
| **设计目的** | **性能优化**，减少连接建立开销                 | **连接保活**，检测“僵尸连接”，保证连接的可靠性 |
| **作用对象** | HTTP请求与响应                                 | TCP连接本身                                    |
| **控制方**   | Web服务器、客户端等应用软件（Nginx、浏览器等） | 操作系统内核                                   |
| **检测方式** | 在超时时间内**等待下一个HTTP请求**的到来       | 在连接空闲时，**发送TCP探测报文**并等待ACK响应 |



C处理程序的过程

## 使用define实现一个max函数

```c
#define MAX(a, b) ({	\
	typeof(a) _a = (a); \
	typeof(b) _b = (b); \
	_a > _b ? _a : _b;  \
})
```



define和内联函数的区别
内存对齐
代码1例子,不长记性的题

```C++
struct a{

char a;

int b;

short c;

};
```
求sizeof(a),

1. 代码二,说出下段代码的错误
```C
char* get_buffer(int size)

{

char a[size]; // char* a = (char*)malloc(size * sizeof(char));

return a;

}
```


1. 代码三，实现`int get_buffer(int size,void *src)`,即分配内存的函数

   

2. 代码四，解释下列输出时，指针过程

```c
    char* a = {1,2,3,4,5,6,7};
    int* ptr = a;
    
    printf("%d",*ptr++);    

    int* ptr+=3;
    
    printf("%d",*ptr++);    


    short* ptr = a;
    
    printf("%d",*ptr++);    
```



虚函数实现原理，子类如果也声明了虚函数，那么虚函数表应该是什么样

虚函数时被“初始化”为0的函数是什么函数（纯虚函数）

有的析构函数为什么设置为虚函数

什么情况下析构函数不需要设置为虚函数

多态介绍下，静态多态和动态多态

纯虚类的作用。

STL中的容器介绍下

红黑树了解吗，介绍下，他的应用有哪些

如果一个文件中统计关键字个数，应该使用那种数据结构。

进程上下文说一下

虚拟内存说一下

## 内存和物理存储映射关系由谁决定

- **谁决定？** **操作系统**决定了哪个虚拟页面映射到哪个物理页帧，并负责在需要时动态地创建、修改和撤销这些映射。
- **谁执行？** **CPU的MMU**负责在硬件层面、以极高的速度执行这些由操作系统定下的映射规则，将程序发出的虚拟地址实时翻译成物理地址。



进程在内存的分布大概为几块

进程间通信方式，简单介绍下，

## 有名管道如何使用

`mkfifo()` `open()` `read()/writer()`、`close()`

单工、`unlink()`清理、原子性写入



信号量如何在不同进程间通信的。

进程间同步的方式

进程和线程的区别

线程的资源由谁进行释放

你觉得你有什么优势

你为什么喜欢技术这个方向（大致这个意思，面试官说最后一个问题的时候，我已经不行了。。）

平时遇到问题怎么解决的

面完信心十足，
现在复盘完后心里拔凉拔凉的。

